{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2eb72195",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-22T21:02:10.254551Z",
     "iopub.status.busy": "2025-03-22T21:02:10.254271Z",
     "iopub.status.idle": "2025-03-22T21:02:10.950000Z",
     "shell.execute_reply": "2025-03-22T21:02:10.949089Z"
    },
    "papermill": {
     "duration": 0.700906,
     "end_time": "2025-03-22T21:02:10.951283",
     "exception": false,
     "start_time": "2025-03-22T21:02:10.250377",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/non-fulfillment/sample_submission.csv\n",
      "/kaggle/input/non-fulfillment/train.csv\n",
      "/kaggle/input/non-fulfillment/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4cd5c43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T21:02:10.957147Z",
     "iopub.status.busy": "2025-03-22T21:02:10.956829Z",
     "iopub.status.idle": "2025-03-22T21:03:11.193527Z",
     "shell.execute_reply": "2025-03-22T21:03:11.192645Z"
    },
    "papermill": {
     "duration": 60.241247,
     "end_time": "2025-03-22T21:03:11.195295",
     "exception": false,
     "start_time": "2025-03-22T21:02:10.954048",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.2/266.2 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.1/64.1 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m430.0/430.0 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.2/352.2 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.7/174.7 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.2/68.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.7/196.7 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.0/71.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.4/324.4 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m818.9/818.9 kB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.3/79.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.3/66.3 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.9/14.9 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m105.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.7/314.7 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.1/806.1 kB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m77.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m93.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m103.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m680.1/680.1 kB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.3/135.3 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "preprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.8.1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mCollecting scikit-learn==1.4.2\r\n",
      "  Downloading scikit_learn-1.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\r\n",
      "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.4.2) (1.26.4)\r\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.4.2) (1.13.1)\r\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.4.2) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.4.2) (3.5.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.5->scikit-learn==1.4.2) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.5->scikit-learn==1.4.2) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.5->scikit-learn==1.4.2) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.5->scikit-learn==1.4.2) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.5->scikit-learn==1.4.2) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.5->scikit-learn==1.4.2) (2.4.1)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.19.5->scikit-learn==1.4.2) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.19.5->scikit-learn==1.4.2) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.19.5->scikit-learn==1.4.2) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.19.5->scikit-learn==1.4.2) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.19.5->scikit-learn==1.4.2) (2024.2.0)\r\n",
      "Downloading scikit_learn-1.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m94.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: scikit-learn\r\n",
      "  Attempting uninstall: scikit-learn\r\n",
      "    Found existing installation: scikit-learn 1.5.2\r\n",
      "    Uninstalling scikit-learn-1.5.2:\r\n",
      "      Successfully uninstalled scikit-learn-1.5.2\r\n",
      "Successfully installed scikit-learn-1.4.2\r\n"
     ]
    }
   ],
   "source": [
    "# Kaggle Notebook에서 AutoGluon 설치 (첫 실행 시 한 번만)\n",
    "!pip install -q --upgrade autogluon\n",
    "!pip install --upgrade scikit-learn==1.4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3694a0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T21:03:11.211474Z",
     "iopub.status.busy": "2025-03-22T21:03:11.211179Z",
     "iopub.status.idle": "2025-03-22T21:03:13.706627Z",
     "shell.execute_reply": "2025-03-22T21:03:13.705919Z"
    },
    "papermill": {
     "duration": 2.505342,
     "end_time": "2025-03-22T21:03:13.708311",
     "exception": false,
     "start_time": "2025-03-22T21:03:11.202969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "from autogluon.tabular import TabularPredictor\n",
    "warnings.filterwarnings(action='ignore')\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cafbde49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T21:03:13.724524Z",
     "iopub.status.busy": "2025-03-22T21:03:13.724060Z",
     "iopub.status.idle": "2025-03-22T21:03:13.727305Z",
     "shell.execute_reply": "2025-03-22T21:03:13.726647Z"
    },
    "papermill": {
     "duration": 0.01231,
     "end_time": "2025-03-22T21:03:13.728448",
     "exception": false,
     "start_time": "2025-03-22T21:03:13.716138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # 데이터 로드 및 전처리\n",
    "# train_data = pd.read_csv('/kaggle/input/non-fulfillment/train.csv')\n",
    "# test_data = pd.read_csv('/kaggle/input/non-fulfillment/test.csv')\n",
    "\n",
    "# # UID 컬럼 제거\n",
    "# train_data.drop(columns=['UID'], inplace=True)\n",
    "# test_data.drop(columns=['UID'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a880927",
   "metadata": {
    "papermill": {
     "duration": 0.00683,
     "end_time": "2025-03-22T21:03:13.742443",
     "exception": false,
     "start_time": "2025-03-22T21:03:13.735613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8200622d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T21:03:13.757714Z",
     "iopub.status.busy": "2025-03-22T21:03:13.757427Z",
     "iopub.status.idle": "2025-03-22T21:03:14.103493Z",
     "shell.execute_reply": "2025-03-22T21:03:14.102784Z"
    },
    "papermill": {
     "duration": 0.35557,
     "end_time": "2025-03-22T21:03:14.105053",
     "exception": false,
     "start_time": "2025-03-22T21:03:13.749483",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. 데이터 로드 및 UID 제거\n",
    "train_data = pd.read_csv('/kaggle/input/non-fulfillment/train.csv')\n",
    "test_data = pd.read_csv('/kaggle/input/non-fulfillment/test.csv')\n",
    "train_data.drop(columns=['UID'], inplace=True)\n",
    "test_data.drop(columns=['UID'], inplace=True)\n",
    "\n",
    "# 2. 범주형 변수 처리 (라벨 인코딩 & 원-핫 인코딩)\n",
    "# 대상 변수: \"주거 형태\", \"현재 직장 근속 연수\", \"대출 목적\", \"대출 상환 기간\"\n",
    "label_enc = LabelEncoder()\n",
    "train_data[\"현재 직장 근속 연수\"] = label_enc.fit_transform(train_data[\"현재 직장 근속 연수\"])\n",
    "test_data[\"현재 직장 근속 연수\"] = label_enc.transform(test_data[\"현재 직장 근속 연수\"])\n",
    "\n",
    "train_data = pd.get_dummies(train_data, columns=[\"주거 형태\", \"대출 목적\", \"대출 상환 기간\"], drop_first=True)\n",
    "test_data = pd.get_dummies(test_data, columns=[\"주거 형태\", \"대출 목적\", \"대출 상환 기간\"], drop_first=True)\n",
    "\n",
    "# 3. 수치형 변수 변환 (로그 변환 및 \"연체 없음\" 컬럼 추가)\n",
    "log_columns = [\"현재 미상환 신용액\", \"월 상환 부채액\", \"현재 대출 잔액\"]\n",
    "for col in log_columns:\n",
    "    train_data[col] = np.log1p(train_data[col])\n",
    "    test_data[col] = np.log1p(test_data[col])\n",
    "\n",
    "# \"마지막 연체 이후 경과 개월 수\"가 0이면 \"연체 없음\" 컬럼 생성\n",
    "train_data[\"연체 없음\"] = (train_data[\"마지막 연체 이후 경과 개월 수\"] == 0).astype(int)\n",
    "test_data[\"연체 없음\"] = (test_data[\"마지막 연체 이후 경과 개월 수\"] == 0).astype(int)\n",
    "\n",
    "# 4. 결측값 처리 (SimpleImputer: 중간값으로 대체)\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "# train_data의 경우, 타겟(\"채무 불이행 여부\")과 특성을 분리하여 처리한 후 다시 합칩니다.\n",
    "target = \"채무 불이행 여부\"\n",
    "train_features = train_data.drop(columns=[target])\n",
    "train_target = train_data[target]\n",
    "\n",
    "train_features_imputed = pd.DataFrame(imputer.fit_transform(train_features), \n",
    "                                      columns=train_features.columns)\n",
    "test_data = pd.DataFrame(imputer.transform(test_data), columns=test_data.columns)\n",
    "\n",
    "# 5. 데이터 스케일링 (StandardScaler 적용)\n",
    "scaler = StandardScaler()\n",
    "train_features_scaled = pd.DataFrame(scaler.fit_transform(train_features_imputed), \n",
    "                                       columns=train_features_imputed.columns)\n",
    "test_data = pd.DataFrame(scaler.transform(test_data), columns=test_data.columns)\n",
    "\n",
    "# 6. 불균형 데이터 처리 (SMOTE 적용)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(train_features_scaled, train_target)\n",
    "# 재조합: SMOTE 처리된 데이터프레임을 train_data로 재정의합니다.\n",
    "train_data = pd.concat([pd.DataFrame(X_resampled, columns=train_features_scaled.columns), \n",
    "                        pd.DataFrame(y_resampled, columns=[target])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55fbc21b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T21:03:14.121015Z",
     "iopub.status.busy": "2025-03-22T21:03:14.120696Z",
     "iopub.status.idle": "2025-03-22T21:03:14.148144Z",
     "shell.execute_reply": "2025-03-22T21:03:14.147245Z"
    },
    "papermill": {
     "duration": 0.036639,
     "end_time": "2025-03-22T21:03:14.149374",
     "exception": false,
     "start_time": "2025-03-22T21:03:14.112735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>연간 소득</th>\n",
       "      <th>현재 직장 근속 연수</th>\n",
       "      <th>체납 세금 압류 횟수</th>\n",
       "      <th>개설된 신용계좌 수</th>\n",
       "      <th>신용 거래 연수</th>\n",
       "      <th>최대 신용한도</th>\n",
       "      <th>신용 문제 발생 횟수</th>\n",
       "      <th>마지막 연체 이후 경과 개월 수</th>\n",
       "      <th>개인 파산 횟수</th>\n",
       "      <th>현재 대출 잔액</th>\n",
       "      <th>...</th>\n",
       "      <th>대출 목적_여행 자금</th>\n",
       "      <th>대출 목적_의료비</th>\n",
       "      <th>대출 목적_이사 비용</th>\n",
       "      <th>대출 목적_자동차 구매</th>\n",
       "      <th>대출 목적_주택 개보수</th>\n",
       "      <th>대출 목적_주택 구매</th>\n",
       "      <th>대출 목적_휴가 비용</th>\n",
       "      <th>대출 상환 기간_장기 상환</th>\n",
       "      <th>연체 없음</th>\n",
       "      <th>채무 불이행 여부</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.155206</td>\n",
       "      <td>-0.965030</td>\n",
       "      <td>-0.279027</td>\n",
       "      <td>-0.703173</td>\n",
       "      <td>-0.899120</td>\n",
       "      <td>-0.482924</td>\n",
       "      <td>-0.507403</td>\n",
       "      <td>-0.344278</td>\n",
       "      <td>0.742870</td>\n",
       "      <td>-0.165014</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.132682</td>\n",
       "      <td>-0.126703</td>\n",
       "      <td>-0.020004</td>\n",
       "      <td>-0.097934</td>\n",
       "      <td>-0.31621</td>\n",
       "      <td>-0.051057</td>\n",
       "      <td>-0.024502</td>\n",
       "      <td>-0.658553</td>\n",
       "      <td>-0.063372</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.128597</td>\n",
       "      <td>-0.965030</td>\n",
       "      <td>-0.279027</td>\n",
       "      <td>-1.568910</td>\n",
       "      <td>-0.663217</td>\n",
       "      <td>-0.507808</td>\n",
       "      <td>-0.507403</td>\n",
       "      <td>-0.993935</td>\n",
       "      <td>-0.442309</td>\n",
       "      <td>1.426284</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.132682</td>\n",
       "      <td>-0.126703</td>\n",
       "      <td>-0.020004</td>\n",
       "      <td>-0.097934</td>\n",
       "      <td>-0.31621</td>\n",
       "      <td>-0.051057</td>\n",
       "      <td>-0.024502</td>\n",
       "      <td>-0.658553</td>\n",
       "      <td>-0.063372</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.563024</td>\n",
       "      <td>0.537992</td>\n",
       "      <td>-0.279027</td>\n",
       "      <td>-0.053870</td>\n",
       "      <td>-0.149779</td>\n",
       "      <td>-0.426087</td>\n",
       "      <td>0.302886</td>\n",
       "      <td>2.154402</td>\n",
       "      <td>3.113228</td>\n",
       "      <td>-1.077898</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.132682</td>\n",
       "      <td>-0.126703</td>\n",
       "      <td>-0.020004</td>\n",
       "      <td>-0.097934</td>\n",
       "      <td>-0.31621</td>\n",
       "      <td>-0.051057</td>\n",
       "      <td>-0.024502</td>\n",
       "      <td>-0.658553</td>\n",
       "      <td>-0.063372</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.777310</td>\n",
       "      <td>1.139201</td>\n",
       "      <td>-0.279027</td>\n",
       "      <td>0.595432</td>\n",
       "      <td>-0.704847</td>\n",
       "      <td>-0.476099</td>\n",
       "      <td>0.302886</td>\n",
       "      <td>-0.444225</td>\n",
       "      <td>0.742870</td>\n",
       "      <td>-0.911207</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.132682</td>\n",
       "      <td>-0.126703</td>\n",
       "      <td>-0.020004</td>\n",
       "      <td>-0.097934</td>\n",
       "      <td>-0.31621</td>\n",
       "      <td>-0.051057</td>\n",
       "      <td>-0.024502</td>\n",
       "      <td>-0.658553</td>\n",
       "      <td>-0.063372</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.503292</td>\n",
       "      <td>-0.063217</td>\n",
       "      <td>-0.279027</td>\n",
       "      <td>-0.270305</td>\n",
       "      <td>0.863219</td>\n",
       "      <td>-0.174536</td>\n",
       "      <td>-0.507403</td>\n",
       "      <td>0.055511</td>\n",
       "      <td>-0.442309</td>\n",
       "      <td>1.678079</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.132682</td>\n",
       "      <td>-0.126703</td>\n",
       "      <td>-0.020004</td>\n",
       "      <td>-0.097934</td>\n",
       "      <td>-0.31621</td>\n",
       "      <td>-0.051057</td>\n",
       "      <td>-0.024502</td>\n",
       "      <td>1.518481</td>\n",
       "      <td>-0.063372</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      연간 소득  현재 직장 근속 연수  체납 세금 압류 횟수  개설된 신용계좌 수  신용 거래 연수   최대 신용한도  \\\n",
       "0 -0.155206    -0.965030    -0.279027   -0.703173 -0.899120 -0.482924   \n",
       "1 -0.128597    -0.965030    -0.279027   -1.568910 -0.663217 -0.507808   \n",
       "2 -0.563024     0.537992    -0.279027   -0.053870 -0.149779 -0.426087   \n",
       "3 -0.777310     1.139201    -0.279027    0.595432 -0.704847 -0.476099   \n",
       "4  1.503292    -0.063217    -0.279027   -0.270305  0.863219 -0.174536   \n",
       "\n",
       "   신용 문제 발생 횟수  마지막 연체 이후 경과 개월 수  개인 파산 횟수  현재 대출 잔액  ...  대출 목적_여행 자금  \\\n",
       "0    -0.507403          -0.344278  0.742870 -0.165014  ...    -0.132682   \n",
       "1    -0.507403          -0.993935 -0.442309  1.426284  ...    -0.132682   \n",
       "2     0.302886           2.154402  3.113228 -1.077898  ...    -0.132682   \n",
       "3     0.302886          -0.444225  0.742870 -0.911207  ...    -0.132682   \n",
       "4    -0.507403           0.055511 -0.442309  1.678079  ...    -0.132682   \n",
       "\n",
       "   대출 목적_의료비  대출 목적_이사 비용  대출 목적_자동차 구매  대출 목적_주택 개보수  대출 목적_주택 구매  \\\n",
       "0  -0.126703    -0.020004     -0.097934      -0.31621    -0.051057   \n",
       "1  -0.126703    -0.020004     -0.097934      -0.31621    -0.051057   \n",
       "2  -0.126703    -0.020004     -0.097934      -0.31621    -0.051057   \n",
       "3  -0.126703    -0.020004     -0.097934      -0.31621    -0.051057   \n",
       "4  -0.126703    -0.020004     -0.097934      -0.31621    -0.051057   \n",
       "\n",
       "   대출 목적_휴가 비용  대출 상환 기간_장기 상환     연체 없음  채무 불이행 여부  \n",
       "0    -0.024502       -0.658553 -0.063372          0  \n",
       "1    -0.024502       -0.658553 -0.063372          0  \n",
       "2    -0.024502       -0.658553 -0.063372          1  \n",
       "3    -0.024502       -0.658553 -0.063372          1  \n",
       "4    -0.024502        1.518481 -0.063372          0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1d3dd62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T21:03:14.170703Z",
     "iopub.status.busy": "2025-03-22T21:03:14.170377Z",
     "iopub.status.idle": "2025-03-22T22:03:31.668176Z",
     "shell.execute_reply": "2025-03-22T22:03:31.667362Z"
    },
    "papermill": {
     "duration": 3617.509218,
     "end_time": "2025-03-22T22:03:31.669795",
     "exception": false,
     "start_time": "2025-03-22T21:03:14.160577",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250322_210314\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP PREEMPT_DYNAMIC Sun Nov 10 10:07:59 UTC 2024\n",
      "CPU Count:          4\n",
      "Memory Avail:       30.16 GB / 31.35 GB (96.2%)\n",
      "Disk Space Avail:   19.50 GB / 19.52 GB (99.9%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=2, num_bag_folds=5, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 900s of the 3600s of remaining time (25%).\n",
      "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
      "2025-03-22 21:03:16,680\tINFO worker.py:1810 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\t\tContext path: \"/kaggle/working/AutogluonModels/ag-20250322_210314/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Running DyStack sub-fit ...\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Beginning AutoGluon training ... Time limit = 896s\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m AutoGluon will save models to \"/kaggle/working/AutogluonModels/ag-20250322_210314/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Train Data Rows:    11712\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Train Data Columns: 31\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Label Column:       채무 불이행 여부\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Problem Type:       binary\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Preprocessing data ...\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Using Feature Generators to preprocess the data ...\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \tAvailable Memory:                    30401.82 MB\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \tTrain Data (Original)  Memory Usage: 2.77 MB (0.0% of available memory)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \tStage 1 Generators:\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t\t\tNote: Converting 9 features to boolean dtype as they only contain 2 unique values.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \tStage 2 Generators:\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \tStage 3 Generators:\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \tStage 4 Generators:\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \tStage 5 Generators:\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t\t('float', []) : 31 | ['연간 소득', '현재 직장 근속 연수', '체납 세금 압류 횟수', '개설된 신용계좌 수', '신용 거래 연수', ...]\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t\t('float', [])     : 22 | ['연간 소득', '현재 직장 근속 연수', '체납 세금 압류 횟수', '개설된 신용계좌 수', '신용 거래 연수', ...]\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t\t('int', ['bool']) :  9 | ['주거 형태_주택 담보 대출 (비거주 중)', '대출 목적_고액 구매', '대출 목적_교육비', '대출 목적_소규모 사업 자금', '대출 목적_여행 자금', ...]\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.2s = Fit runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t31 features in original data used to generate 31 features in processed data.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \tTrain Data (Processed) Memory Usage: 2.07 MB (0.0% of available memory)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Data preprocessing and feature engineering runtime = 0.24s ...\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m User-specified model hyperparameters to be fit:\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m {\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m }\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m AutoGluon will fit 3 stack levels (L1 to L3) ...\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 398.04s of the 895.79s of remaining time.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.7755\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.71s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.08s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 397.18s of the 894.94s of remaining time.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.8341\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.02s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.08s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 397.06s of the 894.82s of remaining time.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=461)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.473331\n",
      "\u001b[36m(_ray_fit pid=605)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.470261\u001b[32m [repeated 5x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.8542\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t19.73s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t2.47s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 374.09s of the 871.85s of remaining time.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.8601\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t10.58s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.53s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 360.31s of the 858.07s of remaining time.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.872\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t3.62s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.49s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 355.91s of the 853.67s of remaining time.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.872\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t3.63s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.49s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Fitting model: CatBoost_BAG_L1 ... Training model for up to 351.47s of the 849.23s of remaining time.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.08%)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.8645\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t24.8s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.03s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 323.84s of the 821.59s of remaining time.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.8818\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t1.69s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.57s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 321.13s of the 818.89s of remaining time.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.8819\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t1.63s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.57s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 318.48s of the 816.24s of remaining time.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.08%)\n",
      "\u001b[36m(_ray_fit pid=1105)\u001b[0m No improvement since epoch 9: early stopping\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.7719\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t40.44s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.28s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Fitting model: XGBoost_BAG_L1 ... Training model for up to 275.27s of the 773.03s of remaining time.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.10%)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.8564\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t9.71s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.34s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 262.39s of the 760.15s of remaining time.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \tWarning: Exception caused NeuralNetTorch_BAG_L1 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=1531, ip=172.19.2.2)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=1531, ip=172.19.2.2)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 255.90s of the 753.66s of remaining time.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.12%)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.8683\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t18.38s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.72s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 233.85s of the 731.61s of remaining time.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.09%)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.8639\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t19.01s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.03s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 211.71s of the 709.47s of remaining time.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \tWarning: Exception caused NeuralNetTorch_r79_BAG_L1 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=2101, ip=172.19.2.2)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=2101, ip=172.19.2.2)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 205.37s of the 703.13s of remaining time.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.08%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=2236)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.450862\n",
      "\u001b[36m(_ray_fit pid=2243)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.459506\n",
      "\u001b[36m(_ray_fit pid=2245)\u001b[0m [2000]\tvalid_set's binary_logloss: 0.435687\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2411)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.436376\n",
      "\u001b[36m(_ray_fit pid=2411)\u001b[0m [2000]\tvalid_set's binary_logloss: 0.433254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.8644\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t23.96s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t2.77s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 177.28s of the 675.04s of remaining time.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.08%)\n",
      "\u001b[36m(_ray_fit pid=2455)\u001b[0m No improvement since epoch 13: early stopping\n",
      "\u001b[36m(_ray_fit pid=2454)\u001b[0m No improvement since epoch 19: early stopping\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2649)\u001b[0m No improvement since epoch 12: early stopping\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.7684\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t75.41s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.48s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 98.78s of the 596.54s of remaining time.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.20%)\n",
      "\u001b[36m(_ray_fit pid=2710)\u001b[0m \tRan out of time, early stopping on iteration 531.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.8696\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t80.64s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.2s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 14.59s of the 512.35s of remaining time.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\u001b[36m(_ray_fit pid=2707)\u001b[0m \tRan out of time, early stopping on iteration 537.\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=2943)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.549067\n",
      "\u001b[36m(_ray_fit pid=2940)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.517517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=2940)\u001b[0m \tRan out of time, early stopping on iteration 2194. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=2940)\u001b[0m \t[2194]\tvalid_set's binary_logloss: 0.495277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=3077)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.525213\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=3077)\u001b[0m \tRan out of time, early stopping on iteration 3628. Best iteration is:\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3077)\u001b[0m \t[3622]\tvalid_set's binary_logloss: 0.486572\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.8335\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t19.17s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t3.67s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 488.88s of remaining time.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \tEnsemble Weights: {'ExtraTreesGini_BAG_L1': 0.261, 'ExtraTreesEntr_BAG_L1': 0.261, 'KNeighborsDist_BAG_L1': 0.174, 'CatBoost_r177_BAG_L1': 0.13, 'CatBoost_BAG_L1': 0.087, 'LightGBMLarge_BAG_L1': 0.043, 'CatBoost_r9_BAG_L1': 0.043}\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.8945\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.69s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.0s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 325.36s of the 488.11s of remaining time.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.09%)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.9228\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t10.97s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.37s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Fitting model: LightGBM_BAG_L2 ... Training model for up to 311.48s of the 474.23s of remaining time.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.09%)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.925\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t10.48s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.15s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 297.89s of the 460.64s of remaining time.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.9148\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t4.65s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.49s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 292.52s of the 455.27s of remaining time.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.9149\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t5.4s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.47s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Fitting model: CatBoost_BAG_L2 ... Training model for up to 286.48s of the 449.23s of remaining time.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.12%)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.9254\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t20.48s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.06s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 263.27s of the 426.02s of remaining time.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.9114\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t1.47s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.52s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 260.98s of the 423.73s of remaining time.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.9108\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t1.47s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.52s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 258.72s of the 421.46s of remaining time.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.11%)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.919\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t35.88s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.33s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Fitting model: XGBoost_BAG_L2 ... Training model for up to 220.08s of the 382.83s of remaining time.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.14%)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.9255\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t10.63s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.13s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 206.63s of the 369.38s of remaining time.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \tWarning: Exception caused NeuralNetTorch_BAG_L2 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=4175, ip=172.19.2.2)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=4175, ip=172.19.2.2)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 200.60s of the 363.35s of remaining time.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.18%)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.9237\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t20.0s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.18s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Fitting model: CatBoost_r177_BAG_L2 ... Training model for up to 177.34s of the 340.09s of remaining time.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.12%)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.926\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t17.41s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.04s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Fitting model: NeuralNetTorch_r79_BAG_L2 ... Training model for up to 156.87s of the 319.62s of remaining time.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \tWarning: Exception caused NeuralNetTorch_r79_BAG_L2 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=4744, ip=172.19.2.2)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=4744, ip=172.19.2.2)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Fitting model: LightGBM_r131_BAG_L2 ... Training model for up to 150.92s of the 313.67s of remaining time.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.11%)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.9252\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t15.47s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.51s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Fitting model: NeuralNetFastAI_r191_BAG_L2 ... Training model for up to 132.18s of the 294.92s of remaining time.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.11%)\n",
      "\u001b[36m(_ray_fit pid=5097)\u001b[0m No improvement since epoch 7: early stopping\n",
      "\u001b[36m(_ray_fit pid=5095)\u001b[0m No improvement since epoch 14: early stopping\n",
      "\u001b[36m(_ray_fit pid=5094)\u001b[0m No improvement since epoch 15: early stopping\n",
      "\u001b[36m(_ray_fit pid=5290)\u001b[0m No improvement since epoch 15: early stopping\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.9201\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t63.77s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.37s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Fitting model: CatBoost_r9_BAG_L2 ... Training model for up to 65.47s of the 228.22s of remaining time.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.30%)\n",
      "\u001b[36m(_ray_fit pid=5350)\u001b[0m \tRan out of time, early stopping on iteration 176.\n",
      "\u001b[36m(_ray_fit pid=5502)\u001b[0m \tRan out of time, early stopping on iteration 310.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.9243\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t54.23s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Fitting model: LightGBM_r96_BAG_L2 ... Training model for up to 8.38s of the 171.13s of remaining time.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.08%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=5577)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.350941\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=5574)\u001b[0m \tRan out of time, early stopping on iteration 804. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=5574)\u001b[0m \t[804]\tvalid_set's binary_logloss: 0.336198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=5710)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.331165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=5710)\u001b[0m \tRan out of time, early stopping on iteration 1400. Best iteration is:\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=5710)\u001b[0m \t[1372]\tvalid_set's binary_logloss: 0.329364\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.9207\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t12.81s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t1.23s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 154.98s of remaining time.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \tEnsemble Weights: {'CatBoost_r177_BAG_L2': 0.32, 'XGBoost_BAG_L2': 0.28, 'NeuralNetFastAI_r191_BAG_L2': 0.2, 'NeuralNetFastAI_BAG_L2': 0.12, 'LightGBM_BAG_L2': 0.04, 'LightGBMLarge_BAG_L2': 0.04}\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.9285\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.61s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.0s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Fitting 108 L3 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Fitting model: LightGBMXT_BAG_L3 ... Training model for up to 154.35s of the 154.30s of remaining time.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.09%)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.927\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t8.81s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.12s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Fitting model: LightGBM_BAG_L3 ... Training model for up to 142.76s of the 142.71s of remaining time.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.09%)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.9261\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t9.32s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Fitting model: RandomForestGini_BAG_L3 ... Training model for up to 130.60s of the 130.55s of remaining time.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.926\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t4.45s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.47s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Fitting model: RandomForestEntr_BAG_L3 ... Training model for up to 125.51s of the 125.46s of remaining time.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.9262\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t4.99s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.45s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Fitting model: CatBoost_BAG_L3 ... Training model for up to 119.89s of the 119.85s of remaining time.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.12%)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.9281\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t15.71s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.04s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Fitting model: ExtraTreesGini_BAG_L3 ... Training model for up to 101.47s of the 101.42s of remaining time.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.9262\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t1.39s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.5s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Fitting model: ExtraTreesEntr_BAG_L3 ... Training model for up to 99.33s of the 99.28s of remaining time.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.926\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t1.34s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.53s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L3 ... Training model for up to 97.21s of the 97.17s of remaining time.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.10%)\n",
      "\u001b[36m(_ray_fit pid=6378)\u001b[0m No improvement since epoch 1: early stopping\n",
      "\u001b[36m(_ray_fit pid=6569)\u001b[0m No improvement since epoch 2: early stopping\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.9238\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t30.37s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.28s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Fitting model: XGBoost_BAG_L3 ... Training model for up to 64.07s of the 64.02s of remaining time.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.14%)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.926\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t9.42s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.11s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Fitting model: NeuralNetTorch_BAG_L3 ... Training model for up to 51.55s of the 51.50s of remaining time.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \tWarning: Exception caused NeuralNetTorch_BAG_L3 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=6800, ip=172.19.2.2)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=6800, ip=172.19.2.2)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Fitting model: LightGBMLarge_BAG_L3 ... Training model for up to 45.13s of the 45.08s of remaining time.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.18%)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.926\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t18.63s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.15s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Fitting model: CatBoost_r177_BAG_L3 ... Training model for up to 23.32s of the 23.27s of remaining time.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.12%)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.9277\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t13.16s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.05s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Fitting model: WeightedEnsemble_L4 ... Training model for up to 360.00s of the 7.06s of remaining time.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \tEnsemble Weights: {'RandomForestGini_BAG_L3': 0.2, 'XGBoost_BAG_L2': 0.12, 'CatBoost_r177_BAG_L2': 0.12, 'CatBoost_BAG_L3': 0.12, 'LightGBMLarge_BAG_L3': 0.12, 'NeuralNetFastAI_r191_BAG_L2': 0.08, 'NeuralNetFastAI_BAG_L3': 0.08, 'XGBoost_BAG_L1': 0.04, 'NeuralNetFastAI_BAG_L2': 0.04, 'RandomForestEntr_BAG_L3': 0.04, 'ExtraTreesGini_BAG_L3': 0.04}\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.9293\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t1.06s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m \t0.0s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m AutoGluon training complete, total runtime = 890.08s ... Best model: WeightedEnsemble_L4 | Estimated inference throughput: 200.2 rows/s (2343 batch size)\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/kaggle/working/AutogluonModels/ag-20250322_210314/ds_sub_fit/sub_fit_ho\")\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=248)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                          model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0          CatBoost_r177_BAG_L3       0.932595   0.927689     roc_auc        9.037511      14.418179  619.421780                 0.017555                0.047516          13.156976            3       True         45\n",
      "1               CatBoost_BAG_L3       0.932385   0.928128     roc_auc        9.038936      14.407569  621.978767                 0.018980                0.036906          15.713964            3       True         39\n",
      "2           WeightedEnsemble_L4       0.932315   0.929319     roc_auc        9.662261      16.258993  682.869002                 0.004925                0.001929           1.056918            4       True         46\n",
      "3           WeightedEnsemble_L3       0.932092   0.928500     roc_auc        8.049565      11.325912  492.735042                 0.003422                0.001900           0.610804            3       True         34\n",
      "4             LightGBMXT_BAG_L3       0.931965   0.926981     roc_auc        9.066794      14.487752  615.078632                 0.046838                0.117090           8.813829            3       True         35\n",
      "5               CatBoost_BAG_L2       0.931278   0.925378     roc_auc        7.489251      10.188926  354.446722                 0.022387                0.058446          20.481763            2       True         23\n",
      "6          CatBoost_r177_BAG_L2       0.931164   0.926007     roc_auc        7.488824      10.169264  351.369962                 0.021960                0.038785          17.405004            2       True         29\n",
      "7         ExtraTreesGini_BAG_L3       0.930960   0.926174     roc_auc        9.163898      14.872983  607.652857                 0.143942                0.502320           1.388053            3       True         40\n",
      "8          LightGBM_r131_BAG_L2       0.930559   0.925171     roc_auc        7.664993      10.643517  349.435578                 0.198129                0.513038          15.470619            2       True         30\n",
      "9               LightGBM_BAG_L2       0.930416   0.924955     roc_auc        7.510995      10.283122  344.443200                 0.044131                0.152642          10.478241            2       True         20\n",
      "10              LightGBM_BAG_L3       0.930313   0.926053     roc_auc        9.056367      14.465858  615.589586                 0.036411                0.095195           9.324783            3       True         36\n",
      "11               XGBoost_BAG_L3       0.930207   0.925952     roc_auc        9.080650      14.482017  615.680682                 0.060694                0.111354           9.415879            3       True         43\n",
      "12               XGBoost_BAG_L2       0.930070   0.925521     roc_auc        7.564732      10.259291  344.595027                 0.097867                0.128812          10.630069            2       True         27\n",
      "13           CatBoost_r9_BAG_L2       0.929785   0.924340     roc_auc        7.525803      10.233901  388.193506                 0.058939                0.103421          54.228548            2       True         32\n",
      "14            LightGBMXT_BAG_L2       0.929596   0.922756     roc_auc        7.586539      10.496039  344.937984                 0.119674                0.365559          10.973026            2       True         19\n",
      "15      RandomForestEntr_BAG_L3       0.929546   0.926224     roc_auc        9.141231      14.819829  611.257310                 0.121274                0.449167           4.992507            3       True         38\n",
      "16      RandomForestGini_BAG_L3       0.929401   0.925953     roc_auc        9.143253      14.837069  610.718472                 0.123297                0.466406           4.453668            3       True         37\n",
      "17       NeuralNetFastAI_BAG_L2       0.929169   0.919008     roc_auc        7.609706      10.456322  369.841481                 0.142841                0.325842          35.876523            2       True         26\n",
      "18          LightGBM_r96_BAG_L2       0.928928   0.920668     roc_auc        7.830167      11.358083  346.779127                 0.363302                1.227604          12.814168            2       True         33\n",
      "19         LightGBMLarge_BAG_L2       0.928352   0.923653     roc_auc        7.572424      10.309917  353.963829                 0.105559                0.179438          19.998870            2       True         28\n",
      "20        ExtraTreesEntr_BAG_L3       0.928189   0.926043     roc_auc        9.162793      14.902977  607.601166                 0.142837                0.532314           1.336362            3       True         41\n",
      "21  NeuralNetFastAI_r191_BAG_L2       0.928001   0.920141     roc_auc        7.633785      10.498493  397.735530                 0.166921                0.368014          63.770572            2       True         31\n",
      "22         LightGBMLarge_BAG_L3       0.927930   0.926008     roc_auc        9.114576      14.524973  624.897064                 0.094620                0.154310          18.632261            3       True         44\n",
      "23       NeuralNetFastAI_BAG_L3       0.927653   0.923754     roc_auc        9.155223      14.647954  636.631631                 0.135267                0.277291          30.366828            3       True         42\n",
      "24      RandomForestEntr_BAG_L2       0.923874   0.914856     roc_auc        7.592786      10.601038  339.364153                 0.125921                0.470559           5.399194            2       True         22\n",
      "25      RandomForestGini_BAG_L2       0.923287   0.914799     roc_auc        7.598243      10.624490  338.617141                 0.131379                0.494011           4.652182            2       True         21\n",
      "26        ExtraTreesEntr_BAG_L2       0.920819   0.910829     roc_auc        7.630912      10.648908  335.430309                 0.164047                0.518429           1.465351            2       True         25\n",
      "27        ExtraTreesGini_BAG_L2       0.920526   0.911377     roc_auc        7.620202      10.653667  335.434841                 0.153338                0.523188           1.469882            2       True         24\n",
      "28          WeightedEnsemble_L2       0.899344   0.894466     roc_auc        1.454567       2.202230  146.862005                 0.004404                0.002335           0.694419            2       True         18\n",
      "29        ExtraTreesEntr_BAG_L1       0.890123   0.881871     roc_auc        0.241229       0.571310    1.633319                 0.241229                0.571310           1.633319            1       True          9\n",
      "30        ExtraTreesGini_BAG_L1       0.889841   0.881751     roc_auc        0.367075       0.569496    1.688142                 0.367075                0.569496           1.688142            1       True          8\n",
      "31      RandomForestGini_BAG_L1       0.885042   0.872040     roc_auc        0.255525       0.494326    3.620181                 0.255525                0.494326           3.620181            1       True          5\n",
      "32      RandomForestEntr_BAG_L1       0.884015   0.871971     roc_auc        0.247514       0.485038    3.634267                 0.247514                0.485038           3.634267            1       True          6\n",
      "33         LightGBMLarge_BAG_L1       0.882484   0.868288     roc_auc        0.302697       0.724519   18.379982                 0.302697                0.724519          18.379982            1       True         12\n",
      "34           CatBoost_r9_BAG_L1       0.881892   0.869633     roc_auc        0.080913       0.200507   80.641517                 0.080913                0.200507          80.641517            1       True         16\n",
      "35         LightGBM_r131_BAG_L1       0.877495   0.864398     roc_auc        0.952307       2.773068   23.961388                 0.952307                2.773068          23.961388            1       True         14\n",
      "36              CatBoost_BAG_L1       0.872697   0.864516     roc_auc        0.416929       0.030701   24.798754                 0.416929                0.030701          24.798754            1       True          7\n",
      "37              LightGBM_BAG_L1       0.872656   0.860050     roc_auc        0.140698       0.530729   10.579446                 0.140698                0.530729          10.579446            1       True          4\n",
      "38         CatBoost_r177_BAG_L1       0.872361   0.863878     roc_auc        0.027028       0.028162   19.006649                 0.027028                0.028162          19.006649            1       True         13\n",
      "39               XGBoost_BAG_L1       0.871872   0.856414     roc_auc        0.116649       0.343621    9.705872                 0.116649                0.343621           9.705872            1       True         11\n",
      "40            LightGBMXT_BAG_L1       0.870627   0.854194     roc_auc        1.602032       2.473338   19.734615                 1.602032                2.473338          19.734615            1       True          3\n",
      "41          LightGBM_r96_BAG_L1       0.843689   0.833544     roc_auc        1.051192       3.672211   19.173350                 1.051192                3.672211          19.173350            1       True         17\n",
      "42        KNeighborsDist_BAG_L1       0.842046   0.834061     roc_auc        0.014294       0.075200    0.019223                 0.014294                0.075200           0.019223            1       True          2\n",
      "43       NeuralNetFastAI_BAG_L1       0.799111   0.771906     roc_auc        2.498148       0.278614   40.444283                 2.498148                0.278614          40.444283            1       True         10\n",
      "44  NeuralNetFastAI_r191_BAG_L1       0.794651   0.768385     roc_auc        0.181692       0.475081   75.410848                 0.181692                0.475081          75.410848            1       True         15\n",
      "45        KNeighborsUnif_BAG_L1       0.788390   0.775519     roc_auc        0.022135       0.076769    0.706473                 0.022135                0.076769           0.706473            1       True          1\n",
      "\t2\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t908s\t = DyStack   runtime |\t2692s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=2.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=2)`\n",
      "Beginning AutoGluon training ... Time limit = 2692s\n",
      "AutoGluon will save models to \"/kaggle/working/AutogluonModels/ag-20250322_210314\"\n",
      "Train Data Rows:    13176\n",
      "Train Data Columns: 31\n",
      "Label Column:       채무 불이행 여부\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    29656.09 MB\n",
      "\tTrain Data (Original)  Memory Usage: 3.12 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 9 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 31 | ['연간 소득', '현재 직장 근속 연수', '체납 세금 압류 횟수', '개설된 신용계좌 수', '신용 거래 연수', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 22 | ['연간 소득', '현재 직장 근속 연수', '체납 세금 압류 횟수', '개설된 신용계좌 수', '신용 거래 연수', ...]\n",
      "\t\t('int', ['bool']) :  9 | ['주거 형태_주택 담보 대출 (비거주 중)', '대출 목적_고액 구매', '대출 목적_교육비', '대출 목적_소규모 사업 자금', '대출 목적_여행 자금', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t31 features in original data used to generate 31 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 2.32 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.23s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 3 stack levels (L1 to L3) ...\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 1196.25s of the 2692.21s of remaining time.\n",
      "\t0.7898\t = Validation score   (roc_auc)\n",
      "\t0.16s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 1195.94s of the 2691.90s of remaining time.\n",
      "\t0.8464\t = Validation score   (roc_auc)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1195.77s of the 2691.74s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
      "\t0.8645\t = Validation score   (roc_auc)\n",
      "\t20.08s\t = Training   runtime\n",
      "\t3.54s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1172.02s of the 2667.99s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
      "\t0.8649\t = Validation score   (roc_auc)\n",
      "\t10.81s\t = Training   runtime\n",
      "\t0.62s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 1157.95s of the 2653.92s of remaining time.\n",
      "\t0.8788\t = Validation score   (roc_auc)\n",
      "\t3.42s\t = Training   runtime\n",
      "\t0.57s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 1153.62s of the 2649.59s of remaining time.\n",
      "\t0.8793\t = Validation score   (roc_auc)\n",
      "\t4.68s\t = Training   runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1148.06s of the 2644.02s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.09%)\n",
      "\t0.8664\t = Validation score   (roc_auc)\n",
      "\t28.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 1117.31s of the 2613.27s of remaining time.\n",
      "\t0.8911\t = Validation score   (roc_auc)\n",
      "\t1.83s\t = Training   runtime\n",
      "\t0.64s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 1114.34s of the 2610.31s of remaining time.\n",
      "\t0.8927\t = Validation score   (roc_auc)\n",
      "\t1.81s\t = Training   runtime\n",
      "\t0.62s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 1111.40s of the 2607.37s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.08%)\n",
      "\t0.7883\t = Validation score   (roc_auc)\n",
      "\t38.67s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 1069.79s of the 2565.76s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.10%)\n",
      "\t0.8588\t = Validation score   (roc_auc)\n",
      "\t9.78s\t = Training   runtime\n",
      "\t0.35s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 1056.74s of the 2552.70s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "\tWarning: Exception caused NeuralNetTorch_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=8765, ip=172.19.2.2)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=8765, ip=172.19.2.2)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 1049.84s of the 2545.80s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.13%)\n",
      "2025-03-22 21:20:53,628\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-03-22 21:20:53,630\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-03-22 21:20:53,631\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.8711\t = Validation score   (roc_auc)\n",
      "\t17.8s\t = Training   runtime\n",
      "\t0.96s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 1028.75s of the 2524.71s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.09%)\n",
      "\t0.8664\t = Validation score   (roc_auc)\n",
      "\t22.69s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 1003.15s of the 2499.11s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r79_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=9396, ip=172.19.2.2)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=9396, ip=172.19.2.2)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 996.92s of the 2492.88s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.08%)\n",
      "2025-03-22 21:21:46,657\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-03-22 21:21:46,658\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-03-22 21:21:46,660\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.8689\t = Validation score   (roc_auc)\n",
      "\t26.99s\t = Training   runtime\n",
      "\t3.47s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 965.68s of the 2461.65s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.09%)\n",
      "\t0.7922\t = Validation score   (roc_auc)\n",
      "\t84.04s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 878.51s of the 2374.47s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.20%)\n",
      "\t0.8727\t = Validation score   (roc_auc)\n",
      "\t97.11s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 778.21s of the 2274.17s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\t0.856\t = Validation score   (roc_auc)\n",
      "\t54.39s\t = Training   runtime\n",
      "\t17.3s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 717.67s of the 2213.64s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r22_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=10553, ip=172.19.2.2)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=10553, ip=172.19.2.2)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 711.37s of the 2207.33s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.38%)\n",
      "2025-03-22 21:26:32,802\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-03-22 21:26:32,806\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-03-22 21:26:32,808\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=10550, ip=172.19.2.2)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\t0.8706\t = Validation score   (roc_auc)\n",
      "\t33.14s\t = Training   runtime\n",
      "\t3.1s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r42_BAG_L1 ... Training model for up to 674.56s of the 2170.53s of remaining time.\n",
      "\t0.8891\t = Validation score   (roc_auc)\n",
      "\t3.25s\t = Training   runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: CatBoost_r137_BAG_L1 ... Training model for up to 670.40s of the 2166.36s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\t0.8634\t = Validation score   (roc_auc)\n",
      "\t29.94s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L1 ... Training model for up to 637.58s of the 2133.54s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.08%)\n",
      "\t0.7845\t = Validation score   (roc_auc)\n",
      "\t19.0s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: CatBoost_r13_BAG_L1 ... Training model for up to 615.32s of the 2111.29s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.20%)\n",
      "\t0.8738\t = Validation score   (roc_auc)\n",
      "\t163.11s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: RandomForest_r195_BAG_L1 ... Training model for up to 449.08s of the 1945.05s of remaining time.\n",
      "\t0.8684\t = Validation score   (roc_auc)\n",
      "\t12.48s\t = Training   runtime\n",
      "\t0.53s\t = Validation runtime\n",
      "Fitting model: LightGBM_r188_BAG_L1 ... Training model for up to 435.80s of the 1931.77s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.13%)\n",
      "\t0.8735\t = Validation score   (roc_auc)\n",
      "\t22.61s\t = Training   runtime\n",
      "\t2.86s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r145_BAG_L1 ... Training model for up to 409.44s of the 1905.40s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.09%)\n",
      "\t0.7978\t = Validation score   (roc_auc)\n",
      "\t77.61s\t = Training   runtime\n",
      "\t0.52s\t = Validation runtime\n",
      "Fitting model: XGBoost_r89_BAG_L1 ... Training model for up to 328.11s of the 1824.07s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.10%)\n",
      "\t0.8604\t = Validation score   (roc_auc)\n",
      "\t9.59s\t = Training   runtime\n",
      "\t0.46s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r30_BAG_L1 ... Training model for up to 315.33s of the 1811.29s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r30_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=12474, ip=172.19.2.2)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=12474, ip=172.19.2.2)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBM_r130_BAG_L1 ... Training model for up to 308.50s of the 1804.47s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.10%)\n",
      "2025-03-22 21:33:15,015\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-03-22 21:33:15,017\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-03-22 21:33:15,019\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.864\t = Validation score   (roc_auc)\n",
      "\t12.15s\t = Training   runtime\n",
      "\t0.58s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r86_BAG_L1 ... Training model for up to 293.12s of the 1789.08s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r86_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=12857, ip=172.19.2.2)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=12857, ip=172.19.2.2)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: CatBoost_r50_BAG_L1 ... Training model for up to 286.68s of the 1782.64s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "2025-03-22 21:33:37,029\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-03-22 21:33:37,030\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-03-22 21:33:37,031\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.8636\t = Validation score   (roc_auc)\n",
      "\t19.73s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r11_BAG_L1 ... Training model for up to 263.81s of the 1759.77s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.08%)\n",
      "\t0.7501\t = Validation score   (roc_auc)\n",
      "\t91.46s\t = Training   runtime\n",
      "\t0.83s\t = Validation runtime\n",
      "Fitting model: XGBoost_r194_BAG_L1 ... Training model for up to 169.21s of the 1665.17s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.14%)\n",
      "\t0.8634\t = Validation score   (roc_auc)\n",
      "\t11.6s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r172_BAG_L1 ... Training model for up to 154.42s of the 1650.39s of remaining time.\n",
      "\t0.8498\t = Validation score   (roc_auc)\n",
      "\t3.01s\t = Training   runtime\n",
      "\t0.5s\t = Validation runtime\n",
      "Fitting model: CatBoost_r69_BAG_L1 ... Training model for up to 150.65s of the 1646.62s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
      "\t0.8649\t = Validation score   (roc_auc)\n",
      "\t22.97s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r103_BAG_L1 ... Training model for up to 124.26s of the 1620.23s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.08%)\n",
      "\t0.7814\t = Validation score   (roc_auc)\n",
      "\t59.89s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r14_BAG_L1 ... Training model for up to 61.26s of the 1557.22s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r14_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=14320, ip=172.19.2.2)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=14320, ip=172.19.2.2)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBM_r161_BAG_L1 ... Training model for up to 54.70s of the 1550.67s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.20%)\n",
      "2025-03-22 21:37:29,166\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-03-22 21:37:29,168\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-03-22 21:37:29,170\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.8736\t = Validation score   (roc_auc)\n",
      "\t36.89s\t = Training   runtime\n",
      "\t3.32s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r143_BAG_L1 ... Training model for up to 13.26s of the 1509.22s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.09%)\n",
      "\t0.7549\t = Validation score   (roc_auc)\n",
      "\t20.59s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 1485.45s of remaining time.\n",
      "\tEnsemble Weights: {'ExtraTreesEntr_BAG_L1': 0.318, 'KNeighborsDist_BAG_L1': 0.182, 'ExtraTreesGini_BAG_L1': 0.182, 'CatBoost_r177_BAG_L1': 0.136, 'ExtraTrees_r42_BAG_L1': 0.091, 'LightGBM_r131_BAG_L1': 0.045, 'CatBoost_r13_BAG_L1': 0.045}\n",
      "\t0.9024\t = Validation score   (roc_auc)\n",
      "\t1.19s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 989.24s of the 1484.15s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.13%)\n",
      "\t0.9304\t = Validation score   (roc_auc)\n",
      "\t11.75s\t = Training   runtime\n",
      "\t0.45s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 973.84s of the 1468.75s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.13%)\n",
      "\t0.9322\t = Validation score   (roc_auc)\n",
      "\t10.9s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 959.76s of the 1454.66s of remaining time.\n",
      "\t0.9206\t = Validation score   (roc_auc)\n",
      "\t7.48s\t = Training   runtime\n",
      "\t0.51s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 951.52s of the 1446.43s of remaining time.\n",
      "\t0.9215\t = Validation score   (roc_auc)\n",
      "\t7.86s\t = Training   runtime\n",
      "\t0.52s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 942.94s of the 1437.85s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.17%)\n",
      "\t0.9317\t = Validation score   (roc_auc)\n",
      "\t30.44s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 909.50s of the 1404.41s of remaining time.\n",
      "\t0.9165\t = Validation score   (roc_auc)\n",
      "\t1.78s\t = Training   runtime\n",
      "\t0.54s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 906.86s of the 1401.77s of remaining time.\n",
      "\t0.9169\t = Validation score   (roc_auc)\n",
      "\t1.74s\t = Training   runtime\n",
      "\t0.58s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 904.21s of the 1399.12s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.15%)\n",
      "\t0.9287\t = Validation score   (roc_auc)\n",
      "\t40.99s\t = Training   runtime\n",
      "\t0.36s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 860.30s of the 1355.20s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.20%)\n",
      "\t0.9315\t = Validation score   (roc_auc)\n",
      "\t12.4s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 844.43s of the 1339.33s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.08%)\n",
      "\tWarning: Exception caused NeuralNetTorch_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=16228, ip=172.19.2.2)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=16228, ip=172.19.2.2)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 838.07s of the 1332.97s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.25%)\n",
      "2025-03-22 21:41:07,278\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-03-22 21:41:07,280\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-03-22 21:41:07,281\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.9311\t = Validation score   (roc_auc)\n",
      "\t25.2s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L2 ... Training model for up to 809.82s of the 1304.73s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.17%)\n",
      "\t0.9315\t = Validation score   (roc_auc)\n",
      "\t23.16s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L2 ... Training model for up to 783.54s of the 1278.45s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.08%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r79_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=16881, ip=172.19.2.2)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=16881, ip=172.19.2.2)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBM_r131_BAG_L2 ... Training model for up to 777.10s of the 1272.01s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.16%)\n",
      "2025-03-22 21:42:08,313\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-03-22 21:42:08,315\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-03-22 21:42:08,316\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.9321\t = Validation score   (roc_auc)\n",
      "\t17.83s\t = Training   runtime\n",
      "\t0.7s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L2 ... Training model for up to 756.13s of the 1251.04s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.15%)\n",
      "\t0.9284\t = Validation score   (roc_auc)\n",
      "\t82.4s\t = Training   runtime\n",
      "\t0.48s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L2 ... Training model for up to 670.37s of the 1165.27s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.42%)\n",
      "\t0.9317\t = Validation score   (roc_auc)\n",
      "\t146.87s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L2 ... Training model for up to 520.11s of the 1015.01s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.11%)\n",
      "\t0.93\t = Validation score   (roc_auc)\n",
      "\t22.79s\t = Training   runtime\n",
      "\t3.46s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L2 ... Training model for up to 493.59s of the 988.50s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.08%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r22_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=18066, ip=172.19.2.2)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=18066, ip=172.19.2.2)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: XGBoost_r33_BAG_L2 ... Training model for up to 487.05s of the 981.96s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.78%)\n",
      "2025-03-22 21:46:57,478\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-03-22 21:46:57,480\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-03-22 21:46:57,481\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.9318\t = Validation score   (roc_auc)\n",
      "\t39.87s\t = Training   runtime\n",
      "\t0.54s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r42_BAG_L2 ... Training model for up to 443.95s of the 938.85s of remaining time.\n",
      "\t0.9266\t = Validation score   (roc_auc)\n",
      "\t4.75s\t = Training   runtime\n",
      "\t0.53s\t = Validation runtime\n",
      "Fitting model: CatBoost_r137_BAG_L2 ... Training model for up to 438.42s of the 933.33s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.11%)\n",
      "\t0.9326\t = Validation score   (roc_auc)\n",
      "\t19.37s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L2 ... Training model for up to 415.59s of the 910.49s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.15%)\n",
      "\t0.9312\t = Validation score   (roc_auc)\n",
      "\t19.49s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: CatBoost_r13_BAG_L2 ... Training model for up to 392.98s of the 887.88s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.42%)\n",
      "\t0.9325\t = Validation score   (roc_auc)\n",
      "\t134.87s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: RandomForest_r195_BAG_L2 ... Training model for up to 254.88s of the 749.78s of remaining time.\n",
      "\t0.9285\t = Validation score   (roc_auc)\n",
      "\t40.32s\t = Training   runtime\n",
      "\t0.54s\t = Validation runtime\n",
      "Fitting model: LightGBM_r188_BAG_L2 ... Training model for up to 213.82s of the 708.72s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.25%)\n",
      "\t0.9257\t = Validation score   (roc_auc)\n",
      "\t17.81s\t = Training   runtime\n",
      "\t0.52s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r145_BAG_L2 ... Training model for up to 192.73s of the 687.63s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.15%)\n",
      "\t0.9303\t = Validation score   (roc_auc)\n",
      "\t80.37s\t = Training   runtime\n",
      "\t0.59s\t = Validation runtime\n",
      "Fitting model: XGBoost_r89_BAG_L2 ... Training model for up to 109.12s of the 604.03s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.20%)\n",
      "\t0.9313\t = Validation score   (roc_auc)\n",
      "\t10.26s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r30_BAG_L2 ... Training model for up to 95.61s of the 590.51s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.08%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r30_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=20037, ip=172.19.2.2)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=20037, ip=172.19.2.2)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBM_r130_BAG_L2 ... Training model for up to 89.17s of the 584.08s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.20%)\n",
      "2025-03-22 21:53:35,698\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-03-22 21:53:35,699\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-03-22 21:53:35,701\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.9307\t = Validation score   (roc_auc)\n",
      "\t14.16s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r86_BAG_L2 ... Training model for up to 71.84s of the 566.75s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.08%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r86_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=20428, ip=172.19.2.2)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=20428, ip=172.19.2.2)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: CatBoost_r50_BAG_L2 ... Training model for up to 65.46s of the 560.37s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.11%)\n",
      "2025-03-22 21:53:59,716\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-03-22 21:53:59,718\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-03-22 21:53:59,719\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.9317\t = Validation score   (roc_auc)\n",
      "\t20.83s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r11_BAG_L2 ... Training model for up to 41.75s of the 536.66s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.15%)\n",
      "\t0.9232\t = Validation score   (roc_auc)\n",
      "\t43.11s\t = Training   runtime\n",
      "\t0.93s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 490.23s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_r102_BAG_L2': 0.25, 'LightGBM_BAG_L2': 0.167, 'CatBoost_r137_BAG_L2': 0.167, 'NeuralNetFastAI_r145_BAG_L2': 0.167, 'RandomForest_r195_BAG_L2': 0.125, 'XGBoost_r33_BAG_L2': 0.083, 'NeuralNetFastAI_r191_BAG_L2': 0.042}\n",
      "\t0.9357\t = Validation score   (roc_auc)\n",
      "\t1.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 108 L3 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L3 ... Training model for up to 489.19s of the 489.12s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.11%)\n",
      "\t0.9337\t = Validation score   (roc_auc)\n",
      "\t9.44s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L3 ... Training model for up to 476.95s of the 476.88s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.11%)\n",
      "\t0.9329\t = Validation score   (roc_auc)\n",
      "\t10.33s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L3 ... Training model for up to 463.63s of the 463.56s of remaining time.\n",
      "\t0.9321\t = Validation score   (roc_auc)\n",
      "\t6.34s\t = Training   runtime\n",
      "\t0.5s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L3 ... Training model for up to 456.57s of the 456.50s of remaining time.\n",
      "\t0.9329\t = Validation score   (roc_auc)\n",
      "\t7.09s\t = Training   runtime\n",
      "\t0.53s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L3 ... Training model for up to 448.75s of the 448.68s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.15%)\n",
      "\t0.935\t = Validation score   (roc_auc)\n",
      "\t17.72s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L3 ... Training model for up to 427.84s of the 427.77s of remaining time.\n",
      "\t0.9323\t = Validation score   (roc_auc)\n",
      "\t1.67s\t = Training   runtime\n",
      "\t0.59s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L3 ... Training model for up to 425.29s of the 425.23s of remaining time.\n",
      "\t0.9319\t = Validation score   (roc_auc)\n",
      "\t1.56s\t = Training   runtime\n",
      "\t0.52s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L3 ... Training model for up to 422.96s of the 422.89s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.13%)\n",
      "\t0.9314\t = Validation score   (roc_auc)\n",
      "\t37.2s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L3 ... Training model for up to 382.73s of the 382.66s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.18%)\n",
      "\t0.9327\t = Validation score   (roc_auc)\n",
      "\t10.83s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L3 ... Training model for up to 368.25s of the 368.18s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
      "\tWarning: Exception caused NeuralNetTorch_BAG_L3 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=22387, ip=172.19.2.2)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=22387, ip=172.19.2.2)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBMLarge_BAG_L3 ... Training model for up to 361.94s of the 361.87s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.22%)\n",
      "2025-03-22 21:57:17,819\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-03-22 21:57:17,821\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-03-22 21:57:17,822\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.9314\t = Validation score   (roc_auc)\n",
      "\t21.74s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L3 ... Training model for up to 337.02s of the 336.95s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.15%)\n",
      "\t0.9348\t = Validation score   (roc_auc)\n",
      "\t16.11s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L3 ... Training model for up to 317.92s of the 317.85s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r79_BAG_L3 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=23033, ip=172.19.2.2)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=23033, ip=172.19.2.2)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBM_r131_BAG_L3 ... Training model for up to 311.22s of the 311.15s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.14%)\n",
      "2025-03-22 21:58:08,850\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-03-22 21:58:08,853\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-03-22 21:58:08,854\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.933\t = Validation score   (roc_auc)\n",
      "\t15.43s\t = Training   runtime\n",
      "\t0.51s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L3 ... Training model for up to 292.57s of the 292.50s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.13%)\n",
      "\t0.9324\t = Validation score   (roc_auc)\n",
      "\t71.99s\t = Training   runtime\n",
      "\t0.34s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L3 ... Training model for up to 217.33s of the 217.26s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.37%)\n",
      "\t0.9346\t = Validation score   (roc_auc)\n",
      "\t94.71s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L3 ... Training model for up to 119.30s of the 119.23s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.10%)\n",
      "\t0.9345\t = Validation score   (roc_auc)\n",
      "\t10.63s\t = Training   runtime\n",
      "\t0.43s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L3 ... Training model for up to 105.42s of the 105.35s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r22_BAG_L3 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=24199, ip=172.19.2.2)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=24199, ip=172.19.2.2)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: XGBoost_r33_BAG_L3 ... Training model for up to 98.87s of the 98.80s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.68%)\n",
      "2025-03-22 22:01:40,977\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-03-22 22:01:40,979\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-03-22 22:01:40,982\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.9323\t = Validation score   (roc_auc)\n",
      "\t27.3s\t = Training   runtime\n",
      "\t0.61s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r42_BAG_L3 ... Training model for up to 68.48s of the 68.42s of remaining time.\n",
      "\t0.931\t = Validation score   (roc_auc)\n",
      "\t4.08s\t = Training   runtime\n",
      "\t0.53s\t = Validation runtime\n",
      "Fitting model: CatBoost_r137_BAG_L3 ... Training model for up to 63.66s of the 63.59s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.10%)\n",
      "\t0.9352\t = Validation score   (roc_auc)\n",
      "\t11.48s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L3 ... Training model for up to 49.32s of the 49.25s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.13%)\n",
      "\t0.9337\t = Validation score   (roc_auc)\n",
      "\t18.74s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: CatBoost_r13_BAG_L3 ... Training model for up to 27.42s of the 27.36s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.37%)\n",
      "\t0.9347\t = Validation score   (roc_auc)\n",
      "\t23.87s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L4 ... Training model for up to 360.00s of the -0.05s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_r137_BAG_L3': 0.2, 'NeuralNetFastAI_r102_BAG_L2': 0.12, 'CatBoost_BAG_L3': 0.12, 'NeuralNetFastAI_BAG_L3': 0.12, 'NeuralNetFastAI_r102_BAG_L3': 0.12, 'RandomForestEntr_BAG_L3': 0.08, 'NeuralNetFastAI_r191_BAG_L3': 0.08, 'XGBoost_BAG_L2': 0.04, 'XGBoost_r33_BAG_L2': 0.04, 'RandomForest_r195_BAG_L2': 0.04, 'RandomForestGini_BAG_L3': 0.04}\n",
      "\t0.936\t = Validation score   (roc_auc)\n",
      "\t1.16s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2693.71s ... Best model: WeightedEnsemble_L4 | Estimated inference throughput: 115.2 rows/s (2636 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/kaggle/working/AutogluonModels/ag-20250322_210314\")\n"
     ]
    }
   ],
   "source": [
    "# 타깃 변수 지정\n",
    "label = '채무 불이행 여부'\n",
    "\n",
    "# AutoGluon TabularPredictor 초기화 및 학습\n",
    "predictor = TabularPredictor(label=label, eval_metric='roc_auc').fit(\n",
    "    train_data,\n",
    "    presets='best_quality',       # 높은 성능을 위한 프리셋 사용\n",
    "    num_bag_folds=5,              # 교차 검증 폴드 수 증가\n",
    "    num_stack_levels=2,           # 스택 앙상블 레벨 추가\n",
    "    time_limit=3600               # 학습에 충분한 시간 할당 (예: 1시간)\n",
    ")\n",
    "\n",
    "# 테스트 데이터에 대해 예측 (각 클래스별 확률 예측)\n",
    "preds_proba = predictor.predict_proba(test_data)\n",
    "test_data['채무 불이행 확률'] = preds_proba[1]  # 1번 클래스(채무 불이행)의 확률 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcffc460",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T22:03:31.751968Z",
     "iopub.status.busy": "2025-03-22T22:03:31.751126Z",
     "iopub.status.idle": "2025-03-22T22:03:31.817368Z",
     "shell.execute_reply": "2025-03-22T22:03:31.816502Z"
    },
    "papermill": {
     "duration": 0.109318,
     "end_time": "2025-03-22T22:03:31.818564",
     "exception": false,
     "start_time": "2025-03-22T22:03:31.709246",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoGluon을 이용한 예측 및 제출 파일 생성 완료!\n"
     ]
    }
   ],
   "source": [
    "# 제출 파일 불러오기 및 예측 결과 반영\n",
    "submission = pd.read_csv('/kaggle/input/non-fulfillment/sample_submission.csv')\n",
    "submission['채무 불이행 확률'] = test_data['채무 불이행 확률']\n",
    "submission.to_csv('submission_autogluon.csv', index=False)\n",
    "\n",
    "print(\"AutoGluon을 이용한 예측 및 제출 파일 생성 완료!\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6936185,
     "sourceId": 11122844,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3686.878807,
   "end_time": "2025-03-22T22:03:34.578349",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-22T21:02:07.699542",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
