{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c93a0b14",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-22T08:08:47.970427Z",
     "iopub.status.busy": "2025-03-22T08:08:47.969933Z",
     "iopub.status.idle": "2025-03-22T08:08:48.885933Z",
     "shell.execute_reply": "2025-03-22T08:08:48.884441Z"
    },
    "papermill": {
     "duration": 0.922112,
     "end_time": "2025-03-22T08:08:48.887699",
     "exception": false,
     "start_time": "2025-03-22T08:08:47.965587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/non-fulfillment/sample_submission.csv\n",
      "/kaggle/input/non-fulfillment/train.csv\n",
      "/kaggle/input/non-fulfillment/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da41036c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T08:08:48.894733Z",
     "iopub.status.busy": "2025-03-22T08:08:48.894218Z",
     "iopub.status.idle": "2025-03-22T08:09:53.265328Z",
     "shell.execute_reply": "2025-03-22T08:09:53.264051Z"
    },
    "papermill": {
     "duration": 64.376626,
     "end_time": "2025-03-22T08:09:53.267368",
     "exception": false,
     "start_time": "2025-03-22T08:08:48.890742",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.2/266.2 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.1/64.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m430.0/430.0 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.2/352.2 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.7/174.7 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.2/68.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.7/196.7 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.0/71.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.4/324.4 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m818.9/818.9 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.3/79.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.3/66.3 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.9/14.9 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.7/314.7 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.1/806.1 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m78.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m680.1/680.1 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.3/135.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "preprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.8.1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mCollecting scikit-learn==1.4.2\r\n",
      "  Downloading scikit_learn-1.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\r\n",
      "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.4.2) (1.26.4)\r\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.4.2) (1.13.1)\r\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.4.2) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.4.2) (3.5.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.5->scikit-learn==1.4.2) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.5->scikit-learn==1.4.2) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.5->scikit-learn==1.4.2) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.5->scikit-learn==1.4.2) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.5->scikit-learn==1.4.2) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.5->scikit-learn==1.4.2) (2.4.1)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.19.5->scikit-learn==1.4.2) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.19.5->scikit-learn==1.4.2) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.19.5->scikit-learn==1.4.2) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.19.5->scikit-learn==1.4.2) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.19.5->scikit-learn==1.4.2) (2024.2.0)\r\n",
      "Downloading scikit_learn-1.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m93.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: scikit-learn\r\n",
      "  Attempting uninstall: scikit-learn\r\n",
      "    Found existing installation: scikit-learn 1.5.2\r\n",
      "    Uninstalling scikit-learn-1.5.2:\r\n",
      "      Successfully uninstalled scikit-learn-1.5.2\r\n",
      "Successfully installed scikit-learn-1.4.2\r\n"
     ]
    }
   ],
   "source": [
    "# Kaggle Notebook에서 AutoGluon 설치 (첫 실행 시 한 번만)\n",
    "!pip install -q --upgrade autogluon\n",
    "!pip install --upgrade scikit-learn==1.4.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bff69883",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T08:09:53.282751Z",
     "iopub.status.busy": "2025-03-22T08:09:53.282349Z",
     "iopub.status.idle": "2025-03-22T08:09:56.242259Z",
     "shell.execute_reply": "2025-03-22T08:09:56.241093Z"
    },
    "papermill": {
     "duration": 2.969823,
     "end_time": "2025-03-22T08:09:56.244257",
     "exception": false,
     "start_time": "2025-03-22T08:09:53.274434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "from autogluon.tabular import TabularPredictor\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5fa604a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T08:09:56.260467Z",
     "iopub.status.busy": "2025-03-22T08:09:56.259563Z",
     "iopub.status.idle": "2025-03-22T08:09:56.362801Z",
     "shell.execute_reply": "2025-03-22T08:09:56.361710Z"
    },
    "papermill": {
     "duration": 0.113676,
     "end_time": "2025-03-22T08:09:56.364835",
     "exception": false,
     "start_time": "2025-03-22T08:09:56.251159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 학습/평가 데이터 로드\n",
    "# train_df = pd.read_csv('./train.csv').drop(columns=['UID'])\n",
    "# test_df = pd.read_csv('./test.csv').drop(columns=['UID'])\n",
    "# train_df = pd.read_csv('/kaggle/input/non-fulfillment/train.csv').drop(columns=['UID'])\n",
    "# test_df = pd.read_csv('/kaggle/input/non-fulfillment/test.csv').drop(columns=['UID'])\n",
    "# 데이터 로드 및 전처리\n",
    "train_data = pd.read_csv('/kaggle/input/non-fulfillment/train.csv')\n",
    "test_data = pd.read_csv('/kaggle/input/non-fulfillment/test.csv')\n",
    "\n",
    "# UID 컬럼 제거\n",
    "train_data.drop(columns=['UID'], inplace=True)\n",
    "test_data.drop(columns=['UID'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec741642",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T08:09:56.379876Z",
     "iopub.status.busy": "2025-03-22T08:09:56.379456Z",
     "iopub.status.idle": "2025-03-22T08:09:56.409865Z",
     "shell.execute_reply": "2025-03-22T08:09:56.408714Z"
    },
    "papermill": {
     "duration": 0.039931,
     "end_time": "2025-03-22T08:09:56.411754",
     "exception": false,
     "start_time": "2025-03-22T08:09:56.371823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>주거 형태</th>\n",
       "      <th>연간 소득</th>\n",
       "      <th>현재 직장 근속 연수</th>\n",
       "      <th>체납 세금 압류 횟수</th>\n",
       "      <th>개설된 신용계좌 수</th>\n",
       "      <th>신용 거래 연수</th>\n",
       "      <th>최대 신용한도</th>\n",
       "      <th>신용 문제 발생 횟수</th>\n",
       "      <th>마지막 연체 이후 경과 개월 수</th>\n",
       "      <th>개인 파산 횟수</th>\n",
       "      <th>대출 목적</th>\n",
       "      <th>대출 상환 기간</th>\n",
       "      <th>현재 대출 잔액</th>\n",
       "      <th>현재 미상환 신용액</th>\n",
       "      <th>월 상환 부채액</th>\n",
       "      <th>신용 점수</th>\n",
       "      <th>채무 불이행 여부</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>자가</td>\n",
       "      <td>1941337.5</td>\n",
       "      <td>10년 이상</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>13.4</td>\n",
       "      <td>400597.5</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>부채 통합</td>\n",
       "      <td>단기 상환</td>\n",
       "      <td>390903.0</td>\n",
       "      <td>225457.5</td>\n",
       "      <td>8806.5</td>\n",
       "      <td>767</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>월세</td>\n",
       "      <td>1979505.0</td>\n",
       "      <td>10년 이상</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>15.1</td>\n",
       "      <td>360679.5</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>부채 통합</td>\n",
       "      <td>단기 상환</td>\n",
       "      <td>1002184.5</td>\n",
       "      <td>64749.0</td>\n",
       "      <td>24961.5</td>\n",
       "      <td>767</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>월세</td>\n",
       "      <td>1356381.0</td>\n",
       "      <td>4년</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>18.8</td>\n",
       "      <td>491770.5</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>3</td>\n",
       "      <td>부채 통합</td>\n",
       "      <td>단기 상환</td>\n",
       "      <td>227775.0</td>\n",
       "      <td>487644.0</td>\n",
       "      <td>12069.0</td>\n",
       "      <td>800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>월세</td>\n",
       "      <td>1049017.5</td>\n",
       "      <td>6년</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15</td>\n",
       "      <td>14.8</td>\n",
       "      <td>411546.0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>부채 통합</td>\n",
       "      <td>단기 상환</td>\n",
       "      <td>251383.5</td>\n",
       "      <td>413211.0</td>\n",
       "      <td>31749.0</td>\n",
       "      <td>796</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>월세</td>\n",
       "      <td>4320217.5</td>\n",
       "      <td>2년</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>26.1</td>\n",
       "      <td>895288.5</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>부채 통합</td>\n",
       "      <td>장기 상환</td>\n",
       "      <td>1163176.5</td>\n",
       "      <td>78991.5</td>\n",
       "      <td>5862.0</td>\n",
       "      <td>751</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  주거 형태      연간 소득 현재 직장 근속 연수  체납 세금 압류 횟수  개설된 신용계좌 수  신용 거래 연수   최대 신용한도  \\\n",
       "0    자가  1941337.5      10년 이상          0.0           9      13.4  400597.5   \n",
       "1    월세  1979505.0      10년 이상          0.0           5      15.1  360679.5   \n",
       "2    월세  1356381.0          4년          0.0          12      18.8  491770.5   \n",
       "3    월세  1049017.5          6년          0.0          15      14.8  411546.0   \n",
       "4    월세  4320217.5          2년          0.0          11      26.1  895288.5   \n",
       "\n",
       "   신용 문제 발생 횟수  마지막 연체 이후 경과 개월 수  개인 파산 횟수  대출 목적 대출 상환 기간   현재 대출 잔액  \\\n",
       "0            0                 24         1  부채 통합    단기 상환   390903.0   \n",
       "1            0                 11         0  부채 통합    단기 상환  1002184.5   \n",
       "2            1                 74         3  부채 통합    단기 상환   227775.0   \n",
       "3            1                 22         1  부채 통합    단기 상환   251383.5   \n",
       "4            0                 32         0  부채 통합    장기 상환  1163176.5   \n",
       "\n",
       "   현재 미상환 신용액  월 상환 부채액  신용 점수  채무 불이행 여부  \n",
       "0    225457.5    8806.5    767          0  \n",
       "1     64749.0   24961.5    767          0  \n",
       "2    487644.0   12069.0    800          1  \n",
       "3    413211.0   31749.0    796          1  \n",
       "4     78991.5    5862.0    751          0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a4cafe1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T08:09:56.427548Z",
     "iopub.status.busy": "2025-03-22T08:09:56.427141Z",
     "iopub.status.idle": "2025-03-22T09:10:01.448409Z",
     "shell.execute_reply": "2025-03-22T09:10:01.446867Z"
    },
    "papermill": {
     "duration": 3605.032323,
     "end_time": "2025-03-22T09:10:01.451435",
     "exception": false,
     "start_time": "2025-03-22T08:09:56.419112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250322_080956\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP PREEMPT_DYNAMIC Sun Nov 10 10:07:59 UTC 2024\n",
      "CPU Count:          4\n",
      "Memory Avail:       30.29 GB / 31.35 GB (96.6%)\n",
      "Disk Space Avail:   19.50 GB / 19.52 GB (99.9%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=2, num_bag_folds=5, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 900s of the 3600s of remaining time (25%).\n",
      "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
      "2025-03-22 08:10:00,218\tINFO worker.py:1810 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\t\tContext path: \"/kaggle/working/AutogluonModels/ag-20250322_080956/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Running DyStack sub-fit ...\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Beginning AutoGluon training ... Time limit = 895s\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m AutoGluon will save models to \"/kaggle/working/AutogluonModels/ag-20250322_080956/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Train Data Rows:    8888\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Train Data Columns: 16\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Label Column:       채무 불이행 여부\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Problem Type:       binary\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Preprocessing data ...\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Using Feature Generators to preprocess the data ...\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \tAvailable Memory:                    30533.50 MB\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \tTrain Data (Original)  Memory Usage: 3.94 MB (0.0% of available memory)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \tStage 1 Generators:\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \tStage 2 Generators:\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \tStage 3 Generators:\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t\tFitting CategoryFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \tStage 4 Generators:\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \tStage 5 Generators:\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t\t('float', [])  : 7 | ['연간 소득', '체납 세금 압류 횟수', '신용 거래 연수', '최대 신용한도', '현재 대출 잔액', ...]\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t\t('int', [])    : 5 | ['개설된 신용계좌 수', '신용 문제 발생 횟수', '마지막 연체 이후 경과 개월 수', '개인 파산 횟수', '신용 점수']\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t\t('object', []) : 4 | ['주거 형태', '현재 직장 근속 연수', '대출 목적', '대출 상환 기간']\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t\t('category', [])  : 3 | ['주거 형태', '현재 직장 근속 연수', '대출 목적']\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t\t('float', [])     : 7 | ['연간 소득', '체납 세금 압류 횟수', '신용 거래 연수', '최대 신용한도', '현재 대출 잔액', ...]\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t\t('int', [])       : 5 | ['개설된 신용계좌 수', '신용 문제 발생 횟수', '마지막 연체 이후 경과 개월 수', '개인 파산 횟수', '신용 점수']\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t\t('int', ['bool']) : 1 | ['대출 상환 기간']\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.1s = Fit runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t16 features in original data used to generate 16 features in processed data.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \tTrain Data (Processed) Memory Usage: 0.85 MB (0.0% of available memory)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Data preprocessing and feature engineering runtime = 0.14s ...\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m User-specified model hyperparameters to be fit:\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m {\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m }\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m AutoGluon will fit 3 stack levels (L1 to L3) ...\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 397.43s of the 894.42s of remaining time.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.5957\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.91s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.06s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 392.18s of the 889.18s of remaining time.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.5918\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.02s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.05s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 392.10s of the 889.10s of remaining time.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.7436\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t11.44s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.18s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 377.02s of the 874.02s of remaining time.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.7364\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t8.2s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 365.18s of the 862.17s of remaining time.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.7215\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t3.7s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.48s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 360.79s of the 857.79s of remaining time.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.7256\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t4.08s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.47s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Fitting model: CatBoost_BAG_L1 ... Training model for up to 356.08s of the 853.07s of remaining time.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.744\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t22.11s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.04s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 330.54s of the 827.54s of remaining time.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.7256\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t1.67s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.53s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 328.04s of the 825.04s of remaining time.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.7278\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t1.65s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.53s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 325.56s of the 822.55s of remaining time.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\u001b[36m(_ray_fit pid=1017)\u001b[0m No improvement since epoch 5: early stopping\n",
      "\u001b[36m(_ray_fit pid=1203)\u001b[0m No improvement since epoch 9: early stopping\u001b[32m [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.7332\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t41.72s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.43s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Fitting model: XGBoost_BAG_L1 ... Training model for up to 280.31s of the 777.30s of remaining time.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.7356\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t9.61s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.16s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 266.73s of the 763.73s of remaining time.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \tWarning: Exception caused NeuralNetTorch_BAG_L1 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=1416, ip=172.19.2.2)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=1416, ip=172.19.2.2)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 259.20s of the 756.20s of remaining time.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.7301\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t12.6s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.13s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 242.51s of the 739.51s of remaining time.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.7454\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t18.99s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.05s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 219.88s of the 716.87s of remaining time.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \tWarning: Exception caused NeuralNetTorch_r79_BAG_L1 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=1960, ip=172.19.2.2)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=1960, ip=172.19.2.2)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 211.90s of the 708.90s of remaining time.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.7388\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t12.12s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.44s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 195.74s of the 692.73s of remaining time.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\u001b[36m(_ray_fit pid=2297)\u001b[0m No improvement since epoch 12: early stopping\n",
      "\u001b[36m(_ray_fit pid=2294)\u001b[0m No improvement since epoch 17: early stopping\n",
      "\u001b[36m(_ray_fit pid=2295)\u001b[0m No improvement since epoch 22: early stopping\n",
      "\u001b[36m(_ray_fit pid=2488)\u001b[0m No improvement since epoch 18: early stopping\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.7319\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t91.79s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.48s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 100.16s of the 597.16s of remaining time.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.10%)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.7402\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t51.27s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 44.34s of the 541.33s of remaining time.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.03%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=2759)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.55893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.7478\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t12.68s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t1.32s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 27.70s of the 524.69s of remaining time.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \tWarning: Exception caused NeuralNetTorch_r22_BAG_L1 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=2924, ip=172.19.2.2)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=2924, ip=172.19.2.2)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 19.26s of the 516.26s of remaining time.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.19%)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.7297\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t17.91s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.73s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 494.17s of remaining time.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \tEnsemble Weights: {'LightGBM_r96_BAG_L1': 0.455, 'CatBoost_r177_BAG_L1': 0.227, 'NeuralNetFastAI_BAG_L1': 0.136, 'NeuralNetFastAI_r191_BAG_L1': 0.091, 'KNeighborsUnif_BAG_L1': 0.045, 'ExtraTreesEntr_BAG_L1': 0.045}\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.7503\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.71s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.0s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 328.88s of the 493.38s of remaining time.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.7451\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t9.77s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Fitting model: LightGBM_BAG_L2 ... Training model for up to 315.54s of the 480.03s of remaining time.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.745\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t10.93s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.11s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 300.71s of the 465.21s of remaining time.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.7378\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t5.87s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.52s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 294.14s of the 458.64s of remaining time.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.7404\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t7.17s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.51s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Fitting model: CatBoost_BAG_L2 ... Training model for up to 286.31s of the 450.80s of remaining time.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.7478\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t24.68s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.06s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 258.06s of the 422.56s of remaining time.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.7411\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t1.87s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.58s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 255.35s of the 419.84s of remaining time.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.7412\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t1.8s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.59s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 252.69s of the 417.19s of remaining time.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\u001b[36m(_ray_fit pid=3831)\u001b[0m No improvement since epoch 3: early stopping\n",
      "\u001b[36m(_ray_fit pid=4018)\u001b[0m No improvement since epoch 3: early stopping\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.7361\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t40.71s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.32s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Fitting model: XGBoost_BAG_L2 ... Training model for up to 208.34s of the 372.84s of remaining time.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.09%)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.7412\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t13.17s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.17s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 190.68s of the 355.18s of remaining time.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \tWarning: Exception caused NeuralNetTorch_BAG_L2 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=4234, ip=172.19.2.2)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=4234, ip=172.19.2.2)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 182.64s of the 347.13s of remaining time.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.12%)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.7369\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t19.05s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.12s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Fitting model: CatBoost_r177_BAG_L2 ... Training model for up to 159.60s of the 324.09s of remaining time.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.08%)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.746\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t22.12s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.06s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Fitting model: NeuralNetTorch_r79_BAG_L2 ... Training model for up to 133.72s of the 298.21s of remaining time.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \tWarning: Exception caused NeuralNetTorch_r79_BAG_L2 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=4777, ip=172.19.2.2)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=4777, ip=172.19.2.2)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Fitting model: LightGBM_r131_BAG_L2 ... Training model for up to 125.30s of the 289.80s of remaining time.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.7445\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t13.67s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.27s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Fitting model: NeuralNetFastAI_r191_BAG_L2 ... Training model for up to 107.54s of the 272.04s of remaining time.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\u001b[36m(_ray_fit pid=5110)\u001b[0m No improvement since epoch 8: early stopping\n",
      "\u001b[36m(_ray_fit pid=5112)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 30)\n",
      "\u001b[36m(_ray_fit pid=5303)\u001b[0m No improvement since epoch 9: early stopping\n",
      "\u001b[36m(_ray_fit pid=5113)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 31)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.7298\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t76.78s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.53s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Fitting model: CatBoost_r9_BAG_L2 ... Training model for up to 26.87s of the 191.37s of remaining time.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.20%)\n",
      "\u001b[36m(_ray_fit pid=5356)\u001b[0m \tRan out of time, early stopping on iteration 66.\n",
      "\u001b[36m(_ray_fit pid=5508)\u001b[0m \tRan out of time, early stopping on iteration 125.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.7448\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t24.19s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.23s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 163.27s of remaining time.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \tEnsemble Weights: {'CatBoost_BAG_L2': 0.524, 'LightGBM_BAG_L2': 0.238, 'ExtraTreesGini_BAG_L2': 0.095, 'RandomForestEntr_BAG_L2': 0.048, 'ExtraTreesEntr_BAG_L2': 0.048, 'CatBoost_r177_BAG_L2': 0.048}\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.7487\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.55s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.0s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Fitting 108 L3 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Fitting model: LightGBMXT_BAG_L3 ... Training model for up to 162.72s of the 162.66s of remaining time.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.7422\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t9.47s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.08s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Fitting model: LightGBM_BAG_L3 ... Training model for up to 149.58s of the 149.53s of remaining time.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.7397\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t10.57s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.08s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Fitting model: RandomForestGini_BAG_L3 ... Training model for up to 135.15s of the 135.09s of remaining time.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.7293\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t5.92s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.54s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Fitting model: RandomForestEntr_BAG_L3 ... Training model for up to 128.52s of the 128.46s of remaining time.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.7348\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t7.37s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.54s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Fitting model: CatBoost_BAG_L3 ... Training model for up to 120.49s of the 120.44s of remaining time.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.7454\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t23.53s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.06s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Fitting model: ExtraTreesGini_BAG_L3 ... Training model for up to 93.27s of the 93.22s of remaining time.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.7357\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t1.88s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.56s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Fitting model: ExtraTreesEntr_BAG_L3 ... Training model for up to 90.57s of the 90.51s of remaining time.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.7369\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t1.83s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.59s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L3 ... Training model for up to 87.88s of the 87.82s of remaining time.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "\u001b[36m(_ray_fit pid=6127)\u001b[0m No improvement since epoch 2: early stopping\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.7364\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t41.47s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.39s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Fitting model: XGBoost_BAG_L3 ... Training model for up to 42.75s of the 42.69s of remaining time.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.08%)\n",
      "\u001b[36m(_ray_fit pid=6126)\u001b[0m No improvement since epoch 8: early stopping\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.7377\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t12.83s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.11s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Fitting model: NeuralNetTorch_BAG_L3 ... Training model for up to 26.14s of the 26.08s of remaining time.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \tWarning: Exception caused NeuralNetTorch_BAG_L3 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=6528, ip=172.19.2.2)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=6528, ip=172.19.2.2)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Fitting model: LightGBMLarge_BAG_L3 ... Training model for up to 18.10s of the 18.04s of remaining time.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.11%)\n",
      "\u001b[36m(_ray_fit pid=6658)\u001b[0m \tRan out of time, early stopping on iteration 352. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=6658)\u001b[0m \t[70]\tvalid_set's binary_logloss: 0.560563\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.7363\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t18.03s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.12s\t = Validation runtime\n",
      "\u001b[36m(_ray_fit pid=6664)\u001b[0m \tRan out of time, early stopping on iteration 362. Best iteration is:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6664)\u001b[0m \t[77]\tvalid_set's binary_logloss: 0.55798\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Fitting model: WeightedEnsemble_L4 ... Training model for up to 360.00s of the -4.26s of remaining time.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \tEnsemble Weights: {'LightGBM_r96_BAG_L1': 0.435, 'LightGBM_BAG_L2': 0.174, 'NeuralNetFastAI_BAG_L1': 0.13, 'CatBoost_BAG_L2': 0.087, 'KNeighborsUnif_BAG_L1': 0.043, 'RandomForestEntr_BAG_L2': 0.043, 'ExtraTreesGini_BAG_L2': 0.043, 'ExtraTreesEntr_BAG_L2': 0.043}\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.7502\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.86s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m \t0.0s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m AutoGluon training complete, total runtime = 899.71s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 742.6 rows/s (1778 batch size)\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/kaggle/working/AutogluonModels/ag-20250322_080956/ds_sub_fit/sub_fit_ho\")\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=253)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                          model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0           LightGBM_r96_BAG_L1       0.761622   0.747759     roc_auc        0.333777       1.319896   12.680629                 0.333777                1.319896          12.680629            1       True         17\n",
      "1          CatBoost_r177_BAG_L1       0.761205   0.745357     roc_auc        0.022094       0.046966   18.991116                 0.022094                0.046966          18.991116            1       True         13\n",
      "2               CatBoost_BAG_L1       0.760442   0.744017     roc_auc        0.581232       0.038408   22.105921                 0.581232                0.038408          22.105921            1       True          7\n",
      "3           WeightedEnsemble_L2       0.760121   0.750345     roc_auc        1.775568       2.869423  168.454948                 0.004320                0.001942           0.710992            2       True         19\n",
      "4            CatBoost_r9_BAG_L1       0.759247   0.740159     roc_auc        0.057965       0.087868   51.266340                 0.057965                0.087868          51.266340            1       True         16\n",
      "5           WeightedEnsemble_L4       0.758825   0.750242     roc_auc        5.814716       7.869839  348.952932                 0.005081                0.001932           0.856008            4       True         45\n",
      "6             LightGBMXT_BAG_L1       0.758397   0.743571     roc_auc        1.082735       0.178072   11.437871                 1.082735                0.178072          11.437871            1       True          3\n",
      "7         ExtraTreesGini_BAG_L2       0.758078   0.741147     roc_auc        5.318315       6.602066  303.527134                 0.261663                0.577660           1.871978            2       True         25\n",
      "8           WeightedEnsemble_L3       0.757713   0.748726     roc_auc        5.838617       7.927651  370.764894                 0.004347                0.002020           0.545635            3       True         34\n",
      "9            CatBoost_r9_BAG_L2       0.757598   0.744783     roc_auc        5.100565       6.256406  325.847219                 0.043913                0.231999          24.192063            2       True         33\n",
      "10              CatBoost_BAG_L2       0.757497   0.747763     roc_auc        5.081953       6.084830  326.330880                 0.025301                0.060424          24.675724            2       True         24\n",
      "11         CatBoost_r177_BAG_L2       0.757306   0.745954     roc_auc        5.081287       6.082130  323.777492                 0.024635                0.057724          22.122335            2       True         30\n",
      "12         LightGBM_r131_BAG_L1       0.757224   0.738805     roc_auc        0.208548       0.438819   12.120481                 0.208548                0.438819          12.120481            1       True         14\n",
      "13               XGBoost_BAG_L1       0.757148   0.735555     roc_auc        0.107690       0.157255    9.609619                 0.107690                0.157255           9.609619            1       True         11\n",
      "14              CatBoost_BAG_L3       0.756093   0.745372     roc_auc        6.855475      10.123366  577.917670                 0.024784                0.056323          23.532944            3       True         39\n",
      "15           XGBoost_r33_BAG_L1       0.755694   0.729694     roc_auc        0.225538       0.730277   17.912206                 0.225538                0.730277          17.912206            1       True         18\n",
      "16         LightGBMLarge_BAG_L1       0.755093   0.730061     roc_auc        0.103496       0.134942   12.602865                 0.103496                0.134942          12.602865            1       True         12\n",
      "17            LightGBMXT_BAG_L2       0.754945   0.745133     roc_auc        5.102945       6.125394  311.424613                 0.046293                0.100988           9.769457            2       True         20\n",
      "18        ExtraTreesEntr_BAG_L2       0.754666   0.741234     roc_auc        5.314677       6.611447  303.456811                 0.258025                0.587040           1.801655            2       True         26\n",
      "19               XGBoost_BAG_L3       0.754283   0.737700     roc_auc        6.932256      10.177626  567.213195                 0.101565                0.110583          12.828468            3       True         43\n",
      "20         LightGBM_r131_BAG_L2       0.753897   0.744517     roc_auc        5.208056       6.293458  315.324091                 0.151404                0.269052          13.668935            2       True         31\n",
      "21              LightGBM_BAG_L1       0.753793   0.736403     roc_auc        0.053836       0.103215    8.195494                 0.053836                0.103215           8.195494            1       True          4\n",
      "22              LightGBM_BAG_L2       0.753572   0.745034     roc_auc        5.097483       6.131845  312.581187                 0.040831                0.107439          10.926031            2       True         21\n",
      "23            LightGBMXT_BAG_L3       0.753253   0.742176     roc_auc        6.874571      10.147030  563.859186                 0.043881                0.079986           9.474459            3       True         35\n",
      "24         LightGBMLarge_BAG_L2       0.753131   0.736922     roc_auc        5.140829       6.144172  320.709589                 0.084177                0.119766          19.054433            2       True         29\n",
      "25       NeuralNetFastAI_BAG_L2       0.752828   0.736076     roc_auc        5.269829       6.339844  342.369691                 0.213176                0.315437          40.714535            2       True         27\n",
      "26               XGBoost_BAG_L2       0.752101   0.741249     roc_auc        5.158688       6.190846  314.824841                 0.102036                0.166440          13.169684            2       True         28\n",
      "27              LightGBM_BAG_L3       0.751795   0.739746     roc_auc        6.886214      10.148402  564.956778                 0.055524                0.081358          10.572051            3       True         36\n",
      "28      RandomForestGini_BAG_L2       0.751774   0.737826     roc_auc        5.230727       6.548118  307.526856                 0.174075                0.523712           5.871700            2       True         22\n",
      "29      RandomForestEntr_BAG_L3       0.751687   0.734777     roc_auc        6.994500      10.603474  561.755328                 0.163810                0.536431           7.370601            3       True         38\n",
      "30       NeuralNetFastAI_BAG_L3       0.750784   0.736353     roc_auc        7.023952      10.454368  595.852579                 0.193261                0.387325          41.467853            3       True         42\n",
      "31  NeuralNetFastAI_r191_BAG_L2       0.750766   0.729807     roc_auc        5.322175       6.558191  378.434249                 0.265522                0.533785          76.779093            2       True         32\n",
      "32        ExtraTreesEntr_BAG_L3       0.750719   0.736877     roc_auc        7.086370      10.658340  556.211236                 0.255679                0.591297           1.826509            3       True         41\n",
      "33         LightGBMLarge_BAG_L3       0.749193   0.736309     roc_auc        6.912673      10.186198  572.412718                 0.081982                0.119154          18.027991            3       True         44\n",
      "34      RandomForestEntr_BAG_L2       0.749106   0.740398     roc_auc        5.223814       6.535345  308.821536                 0.167162                0.510939           7.166380            2       True         23\n",
      "35        ExtraTreesGini_BAG_L3       0.748480   0.735734     roc_auc        7.097146      10.631280  556.263303                 0.266455                0.564237           1.878576            3       True         40\n",
      "36  NeuralNetFastAI_r191_BAG_L1       0.745953   0.731907     roc_auc        0.256625       0.481460   91.792669                 0.256625                0.481460          91.792669            1       True         15\n",
      "37      RandomForestGini_BAG_L1       0.744767   0.721536     roc_auc        0.341961       0.483172    3.695592                 0.341961                0.483172           3.695592            1       True          5\n",
      "38       NeuralNetFastAI_BAG_L1       0.743822   0.733160     roc_auc        0.742774       0.427037   41.722974                 0.742774                0.427037          41.722974            1       True         10\n",
      "39      RandomForestGini_BAG_L3       0.743478   0.729330     roc_auc        7.000913      10.610629  560.308244                 0.170223                0.543586           5.923517            3       True         37\n",
      "40        ExtraTreesGini_BAG_L1       0.743129   0.725597     roc_auc        0.440920       0.527319    1.670719                 0.440920                0.527319           1.670719            1       True          8\n",
      "41        ExtraTreesEntr_BAG_L1       0.739864   0.727830     roc_auc        0.396758       0.534953    1.645302                 0.396758                0.534953           1.645302            1       True          9\n",
      "42      RandomForestEntr_BAG_L1       0.738718   0.725594     roc_auc        0.228170       0.467417    4.076229                 0.228170                0.467417           4.076229            1       True          6\n",
      "43        KNeighborsDist_BAG_L1       0.595208   0.591760     roc_auc        0.010645       0.048317    0.016221                 0.010645                0.048317           0.016221            1       True          2\n",
      "44        KNeighborsUnif_BAG_L1       0.593896   0.595661     roc_auc        0.019219       0.057169    0.911267                 0.019219                0.057169           0.911267            1       True          1\n",
      "\t2\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t916s\t = DyStack   runtime |\t2684s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=2.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=2)`\n",
      "Beginning AutoGluon training ... Time limit = 2684s\n",
      "AutoGluon will save models to \"/kaggle/working/AutogluonModels/ag-20250322_080956\"\n",
      "Train Data Rows:    10000\n",
      "Train Data Columns: 16\n",
      "Label Column:       채무 불이행 여부\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    30019.71 MB\n",
      "\tTrain Data (Original)  Memory Usage: 4.94 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 7 | ['연간 소득', '체납 세금 압류 횟수', '신용 거래 연수', '최대 신용한도', '현재 대출 잔액', ...]\n",
      "\t\t('int', [])    : 5 | ['개설된 신용계좌 수', '신용 문제 발생 횟수', '마지막 연체 이후 경과 개월 수', '개인 파산 횟수', '신용 점수']\n",
      "\t\t('object', []) : 4 | ['주거 형태', '현재 직장 근속 연수', '대출 목적', '대출 상환 기간']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 3 | ['주거 형태', '현재 직장 근속 연수', '대출 목적']\n",
      "\t\t('float', [])     : 7 | ['연간 소득', '체납 세금 압류 횟수', '신용 거래 연수', '최대 신용한도', '현재 대출 잔액', ...]\n",
      "\t\t('int', [])       : 5 | ['개설된 신용계좌 수', '신용 문제 발생 횟수', '마지막 연체 이후 경과 개월 수', '개인 파산 횟수', '신용 점수']\n",
      "\t\t('int', ['bool']) : 1 | ['대출 상환 기간']\n",
      "\t0.2s = Fit runtime\n",
      "\t16 features in original data used to generate 16 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.96 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.2s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 3 stack levels (L1 to L3) ...\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 1192.35s of the 2683.44s of remaining time.\n",
      "\t0.5954\t = Validation score   (roc_auc)\n",
      "\t0.5s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 1189.26s of the 2680.35s of remaining time.\n",
      "\t0.5922\t = Validation score   (roc_auc)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1189.15s of the 2680.24s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t0.747\t = Validation score   (roc_auc)\n",
      "\t9.45s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1175.46s of the 2666.55s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t0.7418\t = Validation score   (roc_auc)\n",
      "\t9.02s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 1162.45s of the 2653.54s of remaining time.\n",
      "\t0.7237\t = Validation score   (roc_auc)\n",
      "\t4.01s\t = Training   runtime\n",
      "\t0.54s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 1157.56s of the 2648.65s of remaining time.\n",
      "\t0.7301\t = Validation score   (roc_auc)\n",
      "\t5.37s\t = Training   runtime\n",
      "\t0.52s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1151.34s of the 2642.43s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\t0.7498\t = Validation score   (roc_auc)\n",
      "\t24.52s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 1122.94s of the 2614.03s of remaining time.\n",
      "\t0.7312\t = Validation score   (roc_auc)\n",
      "\t2.45s\t = Training   runtime\n",
      "\t0.58s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 1119.45s of the 2610.54s of remaining time.\n",
      "\t0.7321\t = Validation score   (roc_auc)\n",
      "\t1.89s\t = Training   runtime\n",
      "\t0.58s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 1116.52s of the 2607.61s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t0.7332\t = Validation score   (roc_auc)\n",
      "\t45.85s\t = Training   runtime\n",
      "\t0.37s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 1066.91s of the 2558.00s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "\t0.738\t = Validation score   (roc_auc)\n",
      "\t11.04s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 1051.76s of the 2542.85s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\tWarning: Exception caused NeuralNetTorch_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=8149, ip=172.19.2.2)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=8149, ip=172.19.2.2)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 1043.40s of the 2534.49s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "2025-03-22 08:27:47,471\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-03-22 08:27:47,473\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-03-22 08:27:47,475\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.7343\t = Validation score   (roc_auc)\n",
      "\t13.1s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 1026.29s of the 2517.38s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\t0.7503\t = Validation score   (roc_auc)\n",
      "\t20.69s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 1001.13s of the 2492.22s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r79_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=8751, ip=172.19.2.2)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=8751, ip=172.19.2.2)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 992.79s of the 2483.87s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "2025-03-22 08:28:38,512\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-03-22 08:28:38,516\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-03-22 08:28:38,518\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.7426\t = Validation score   (roc_auc)\n",
      "\t12.19s\t = Training   runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 975.85s of the 2466.94s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t0.7319\t = Validation score   (roc_auc)\n",
      "\t98.85s\t = Training   runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 873.09s of the 2364.18s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.10%)\n",
      "\t0.7457\t = Validation score   (roc_auc)\n",
      "\t52.73s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 816.07s of the 2307.16s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t0.7502\t = Validation score   (roc_auc)\n",
      "\t12.34s\t = Training   runtime\n",
      "\t1.21s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 799.33s of the 2290.42s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r22_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=9838, ip=172.19.2.2)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=9838, ip=172.19.2.2)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 790.36s of the 2281.45s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.19%)\n",
      "2025-03-22 08:32:00,653\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-03-22 08:32:00,658\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-03-22 08:32:00,660\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.7358\t = Validation score   (roc_auc)\n",
      "\t22.4s\t = Training   runtime\n",
      "\t0.63s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r42_BAG_L1 ... Training model for up to 763.95s of the 2255.04s of remaining time.\n",
      "\t0.7257\t = Validation score   (roc_auc)\n",
      "\t3.25s\t = Training   runtime\n",
      "\t0.53s\t = Validation runtime\n",
      "Fitting model: CatBoost_r137_BAG_L1 ... Training model for up to 759.79s of the 2250.88s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t0.7498\t = Validation score   (roc_auc)\n",
      "\t21.95s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L1 ... Training model for up to 733.97s of the 2225.06s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t0.7328\t = Validation score   (roc_auc)\n",
      "\t21.35s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: CatBoost_r13_BAG_L1 ... Training model for up to 708.02s of the 2199.11s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.10%)\n",
      "\t0.7492\t = Validation score   (roc_auc)\n",
      "\t50.91s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForest_r195_BAG_L1 ... Training model for up to 653.20s of the 2144.29s of remaining time.\n",
      "\t0.7192\t = Validation score   (roc_auc)\n",
      "\t9.66s\t = Training   runtime\n",
      "\t0.53s\t = Validation runtime\n",
      "Fitting model: LightGBM_r188_BAG_L1 ... Training model for up to 642.73s of the 2133.82s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\t0.7416\t = Validation score   (roc_auc)\n",
      "\t12.95s\t = Training   runtime\n",
      "\t0.51s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r145_BAG_L1 ... Training model for up to 625.89s of the 2116.97s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t0.7336\t = Validation score   (roc_auc)\n",
      "\t95.8s\t = Training   runtime\n",
      "\t0.78s\t = Validation runtime\n",
      "Fitting model: XGBoost_r89_BAG_L1 ... Training model for up to 525.82s of the 2016.91s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "\t0.743\t = Validation score   (roc_auc)\n",
      "\t9.61s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r30_BAG_L1 ... Training model for up to 511.86s of the 2002.95s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r30_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=11665, ip=172.19.2.2)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=11665, ip=172.19.2.2)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBM_r130_BAG_L1 ... Training model for up to 503.61s of the 1994.70s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "2025-03-22 08:36:47,855\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-03-22 08:36:47,857\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-03-22 08:36:47,858\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.7428\t = Validation score   (roc_auc)\n",
      "\t11.12s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r86_BAG_L1 ... Training model for up to 488.02s of the 1979.11s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r86_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=12032, ip=172.19.2.2)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=12032, ip=172.19.2.2)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: CatBoost_r50_BAG_L1 ... Training model for up to 479.47s of the 1970.56s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "2025-03-22 08:37:11,871\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-03-22 08:37:11,873\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-03-22 08:37:11,874\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.7483\t = Validation score   (roc_auc)\n",
      "\t19.31s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r11_BAG_L1 ... Training model for up to 455.96s of the 1947.04s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t0.7329\t = Validation score   (roc_auc)\n",
      "\t108.15s\t = Training   runtime\n",
      "\t0.86s\t = Validation runtime\n",
      "Fitting model: XGBoost_r194_BAG_L1 ... Training model for up to 343.71s of the 1834.80s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
      "\t0.7362\t = Validation score   (roc_auc)\n",
      "\t9.2s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r172_BAG_L1 ... Training model for up to 330.12s of the 1821.21s of remaining time.\n",
      "\t0.7348\t = Validation score   (roc_auc)\n",
      "\t2.36s\t = Training   runtime\n",
      "\t0.5s\t = Validation runtime\n",
      "Fitting model: CatBoost_r69_BAG_L1 ... Training model for up to 327.01s of the 1818.10s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t0.7503\t = Validation score   (roc_auc)\n",
      "\t22.31s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r103_BAG_L1 ... Training model for up to 300.88s of the 1791.97s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t0.7313\t = Validation score   (roc_auc)\n",
      "\t66.32s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r14_BAG_L1 ... Training model for up to 230.20s of the 1721.29s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r14_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=13440, ip=172.19.2.2)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=13440, ip=172.19.2.2)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBM_r161_BAG_L1 ... Training model for up to 221.91s of the 1713.00s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.10%)\n",
      "2025-03-22 08:41:29,046\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-03-22 08:41:29,048\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-03-22 08:41:29,052\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.7372\t = Validation score   (roc_auc)\n",
      "\t21.63s\t = Training   runtime\n",
      "\t0.86s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r143_BAG_L1 ... Training model for up to 195.69s of the 1686.78s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t0.7426\t = Validation score   (roc_auc)\n",
      "\t31.6s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Fitting model: CatBoost_r70_BAG_L1 ... Training model for up to 160.01s of the 1651.10s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\t0.7476\t = Validation score   (roc_auc)\n",
      "\t32.37s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r156_BAG_L1 ... Training model for up to 123.32s of the 1614.41s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t0.7398\t = Validation score   (roc_auc)\n",
      "\t25.3s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Fitting model: LightGBM_r196_BAG_L1 ... Training model for up to 93.68s of the 1584.77s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\t0.747\t = Validation score   (roc_auc)\n",
      "\t33.01s\t = Training   runtime\n",
      "\t5.31s\t = Validation runtime\n",
      "Fitting model: RandomForest_r39_BAG_L1 ... Training model for up to 54.64s of the 1545.73s of remaining time.\n",
      "\t0.7223\t = Validation score   (roc_auc)\n",
      "\t9.16s\t = Training   runtime\n",
      "\t0.51s\t = Validation runtime\n",
      "Fitting model: CatBoost_r167_BAG_L1 ... Training model for up to 44.70s of the 1535.79s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\t0.7485\t = Validation score   (roc_auc)\n",
      "\t24.1s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r95_BAG_L1 ... Training model for up to 16.03s of the 1507.12s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t0.7236\t = Validation score   (roc_auc)\n",
      "\t25.78s\t = Training   runtime\n",
      "\t0.86s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 1477.03s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_r177_BAG_L1': 0.261, 'LightGBM_r96_BAG_L1': 0.217, 'ExtraTreesEntr_BAG_L1': 0.087, 'NeuralNetFastAI_BAG_L1': 0.087, 'CatBoost_r69_BAG_L1': 0.087, 'NeuralNetFastAI_r143_BAG_L1': 0.087, 'KNeighborsUnif_BAG_L1': 0.043, 'CatBoost_BAG_L1': 0.043, 'CatBoost_r137_BAG_L1': 0.043, 'NeuralNetFastAI_r156_BAG_L1': 0.043}\n",
      "\t0.7538\t = Validation score   (roc_auc)\n",
      "\t1.19s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 983.63s of the 1475.67s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.09%)\n",
      "\t0.7469\t = Validation score   (roc_auc)\n",
      "\t11.19s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 968.41s of the 1460.45s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.09%)\n",
      "\t0.743\t = Validation score   (roc_auc)\n",
      "\t11.76s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 952.42s of the 1444.46s of remaining time.\n",
      "\t0.7365\t = Validation score   (roc_auc)\n",
      "\t8.62s\t = Training   runtime\n",
      "\t0.68s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 942.80s of the 1434.84s of remaining time.\n",
      "\t0.741\t = Validation score   (roc_auc)\n",
      "\t10.97s\t = Training   runtime\n",
      "\t0.6s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 930.97s of the 1423.01s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.12%)\n",
      "\t0.7499\t = Validation score   (roc_auc)\n",
      "\t30.94s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 896.19s of the 1388.23s of remaining time.\n",
      "\t0.7424\t = Validation score   (roc_auc)\n",
      "\t2.19s\t = Training   runtime\n",
      "\t0.65s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 892.98s of the 1385.03s of remaining time.\n",
      "\t0.7415\t = Validation score   (roc_auc)\n",
      "\t2.19s\t = Training   runtime\n",
      "\t0.69s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 889.74s of the 1381.78s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.09%)\n",
      "\t0.7441\t = Validation score   (roc_auc)\n",
      "\t48.53s\t = Training   runtime\n",
      "\t0.42s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 837.05s of the 1329.09s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.42%)\n",
      "\t0.7412\t = Validation score   (roc_auc)\n",
      "\t18.49s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 807.58s of the 1299.63s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "\tWarning: Exception caused NeuralNetTorch_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=16501, ip=172.19.2.2)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=16501, ip=172.19.2.2)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 798.21s of the 1290.25s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.20%)\n",
      "2025-03-22 08:48:32,352\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-03-22 08:48:32,354\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-03-22 08:48:32,356\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.7366\t = Validation score   (roc_auc)\n",
      "\t24.57s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L2 ... Training model for up to 769.33s of the 1261.37s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.12%)\n",
      "\t0.7518\t = Validation score   (roc_auc)\n",
      "\t27.65s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L2 ... Training model for up to 737.52s of the 1229.57s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r79_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=17126, ip=172.19.2.2)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=17126, ip=172.19.2.2)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBM_r131_BAG_L2 ... Training model for up to 729.13s of the 1221.17s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.11%)\n",
      "2025-03-22 08:49:41,407\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-03-22 08:49:41,409\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-03-22 08:49:41,411\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.7424\t = Validation score   (roc_auc)\n",
      "\t16.59s\t = Training   runtime\n",
      "\t0.51s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L2 ... Training model for up to 708.19s of the 1200.23s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.09%)\n",
      "\t0.7387\t = Validation score   (roc_auc)\n",
      "\t92.18s\t = Training   runtime\n",
      "\t0.61s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L2 ... Training model for up to 611.60s of the 1103.65s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.34%)\n",
      "\t0.7481\t = Validation score   (roc_auc)\n",
      "\t118.39s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L2 ... Training model for up to 488.84s of the 980.88s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
      "\t0.7494\t = Validation score   (roc_auc)\n",
      "\t10.76s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L2 ... Training model for up to 473.22s of the 965.26s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r22_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=18249, ip=172.19.2.2)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=18249, ip=172.19.2.2)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: XGBoost_r33_BAG_L2 ... Training model for up to 464.72s of the 956.77s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.64%)\n",
      "2025-03-22 08:54:05,590\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-03-22 08:54:05,592\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-03-22 08:54:05,593\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.7381\t = Validation score   (roc_auc)\n",
      "\t44.8s\t = Training   runtime\n",
      "\t0.36s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r42_BAG_L2 ... Training model for up to 415.55s of the 907.60s of remaining time.\n",
      "\t0.7373\t = Validation score   (roc_auc)\n",
      "\t4.9s\t = Training   runtime\n",
      "\t0.62s\t = Validation runtime\n",
      "Fitting model: CatBoost_r137_BAG_L2 ... Training model for up to 409.70s of the 901.75s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
      "\t0.7506\t = Validation score   (roc_auc)\n",
      "\t22.25s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L2 ... Training model for up to 383.34s of the 875.38s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.09%)\n",
      "\t0.7404\t = Validation score   (roc_auc)\n",
      "\t23.03s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: CatBoost_r13_BAG_L2 ... Training model for up to 356.04s of the 848.09s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.34%)\n",
      "\t0.7502\t = Validation score   (roc_auc)\n",
      "\t79.9s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: RandomForest_r195_BAG_L2 ... Training model for up to 271.60s of the 763.64s of remaining time.\n",
      "\t0.7333\t = Validation score   (roc_auc)\n",
      "\t43.4s\t = Training   runtime\n",
      "\t0.69s\t = Validation runtime\n",
      "Fitting model: LightGBM_r188_BAG_L2 ... Training model for up to 227.27s of the 719.31s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.19%)\n",
      "\t0.7436\t = Validation score   (roc_auc)\n",
      "\t20.14s\t = Training   runtime\n",
      "\t0.35s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r145_BAG_L2 ... Training model for up to 201.47s of the 693.51s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.30%)\n",
      "\t0.7439\t = Validation score   (roc_auc)\n",
      "\t89.29s\t = Training   runtime\n",
      "\t0.82s\t = Validation runtime\n",
      "Fitting model: XGBoost_r89_BAG_L2 ... Training model for up to 104.31s of the 596.36s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.14%)\n",
      "\t0.7444\t = Validation score   (roc_auc)\n",
      "\t13.66s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r30_BAG_L2 ... Training model for up to 86.13s of the 578.18s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r30_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=20132, ip=172.19.2.2)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=20132, ip=172.19.2.2)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBM_r130_BAG_L2 ... Training model for up to 77.39s of the 569.43s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.15%)\n",
      "2025-03-22 09:00:32,895\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-03-22 09:00:32,897\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-03-22 09:00:32,900\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.738\t = Validation score   (roc_auc)\n",
      "\t15.24s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r86_BAG_L2 ... Training model for up to 58.13s of the 550.17s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r86_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=20512, ip=172.19.2.2)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=20512, ip=172.19.2.2)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: CatBoost_r50_BAG_L2 ... Training model for up to 49.28s of the 541.32s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
      "2025-03-22 09:01:00,918\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-03-22 09:01:00,921\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-03-22 09:01:00,923\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.7512\t = Validation score   (roc_auc)\n",
      "\t23.79s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r11_BAG_L2 ... Training model for up to 21.46s of the 513.50s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.09%)\n",
      "\t0.7272\t = Validation score   (roc_auc)\n",
      "\t29.3s\t = Training   runtime\n",
      "\t0.99s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 479.55s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_r177_BAG_L2': 0.6, 'CatBoost_r50_BAG_L2': 0.25, 'NeuralNetFastAI_BAG_L2': 0.15}\n",
      "\t0.7523\t = Validation score   (roc_auc)\n",
      "\t1.06s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 108 L3 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L3 ... Training model for up to 478.47s of the 478.38s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
      "\t0.7449\t = Validation score   (roc_auc)\n",
      "\t10.7s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L3 ... Training model for up to 463.83s of the 463.74s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
      "\t0.7443\t = Validation score   (roc_auc)\n",
      "\t11.98s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L3 ... Training model for up to 447.58s of the 447.50s of remaining time.\n",
      "\t0.7386\t = Validation score   (roc_auc)\n",
      "\t8.5s\t = Training   runtime\n",
      "\t0.6s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L3 ... Training model for up to 438.21s of the 438.12s of remaining time.\n",
      "\t0.7392\t = Validation score   (roc_auc)\n",
      "\t10.72s\t = Training   runtime\n",
      "\t0.61s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L3 ... Training model for up to 426.63s of the 426.54s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.10%)\n",
      "\t0.7469\t = Validation score   (roc_auc)\n",
      "\t27.69s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L3 ... Training model for up to 394.22s of the 394.13s of remaining time.\n",
      "\t0.7359\t = Validation score   (roc_auc)\n",
      "\t2.8s\t = Training   runtime\n",
      "\t0.7s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L3 ... Training model for up to 390.31s of the 390.22s of remaining time.\n",
      "\t0.7372\t = Validation score   (roc_auc)\n",
      "\t2.11s\t = Training   runtime\n",
      "\t0.63s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L3 ... Training model for up to 387.20s of the 387.11s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
      "\t0.7412\t = Validation score   (roc_auc)\n",
      "\t44.4s\t = Training   runtime\n",
      "\t0.39s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L3 ... Training model for up to 338.75s of the 338.67s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.11%)\n",
      "\t0.7418\t = Validation score   (roc_auc)\n",
      "\t15.69s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L3 ... Training model for up to 318.71s of the 318.62s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\tWarning: Exception caused NeuralNetTorch_BAG_L3 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=22386, ip=172.19.2.2)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=22386, ip=172.19.2.2)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBMLarge_BAG_L3 ... Training model for up to 310.34s of the 310.26s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.15%)\n",
      "2025-03-22 09:04:52,082\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-03-22 09:04:52,084\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-03-22 09:04:52,086\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.7355\t = Validation score   (roc_auc)\n",
      "\t22.28s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L3 ... Training model for up to 283.79s of the 283.70s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.10%)\n",
      "\t0.7467\t = Validation score   (roc_auc)\n",
      "\t24.86s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L3 ... Training model for up to 254.82s of the 254.73s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r79_BAG_L3 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=23006, ip=172.19.2.2)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=23006, ip=172.19.2.2)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBM_r131_BAG_L3 ... Training model for up to 246.38s of the 246.29s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.09%)\n",
      "2025-03-22 09:05:56,128\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-03-22 09:05:56,130\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-03-22 09:05:56,131\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.7432\t = Validation score   (roc_auc)\n",
      "\t15.51s\t = Training   runtime\n",
      "\t0.34s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L3 ... Training model for up to 226.52s of the 226.43s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
      "\t0.7411\t = Validation score   (roc_auc)\n",
      "\t105.99s\t = Training   runtime\n",
      "\t0.59s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L3 ... Training model for up to 116.30s of the 116.21s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.26%)\n",
      "\t0.7464\t = Validation score   (roc_auc)\n",
      "\t96.43s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L3 ... Training model for up to 15.38s of the 15.30s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\t0.7469\t = Validation score   (roc_auc)\n",
      "\t10.77s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L4 ... Training model for up to 360.00s of the -0.20s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_r177_BAG_L2': 0.32, 'CatBoost_r69_BAG_L1': 0.24, 'LightGBM_r96_BAG_L1': 0.2, 'NeuralNetFastAI_r143_BAG_L1': 0.12, 'KNeighborsUnif_BAG_L1': 0.04, 'NeuralNetFastAI_BAG_L2': 0.04, 'RandomForestGini_BAG_L3': 0.04}\n",
      "\t0.7533\t = Validation score   (roc_auc)\n",
      "\t1.22s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2685.13s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 785.5 rows/s (2000 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/kaggle/working/AutogluonModels/ag-20250322_080956\")\n"
     ]
    }
   ],
   "source": [
    "# 타깃 변수 지정\n",
    "label = '채무 불이행 여부'\n",
    "\n",
    "# AutoGluon TabularPredictor 초기화 및 학습\n",
    "predictor = TabularPredictor(label=label, eval_metric='roc_auc').fit(\n",
    "    train_data,\n",
    "    presets='best_quality',       # 높은 성능을 위한 프리셋 사용\n",
    "    num_bag_folds=5,              # 교차 검증 폴드 수 증가\n",
    "    num_stack_levels=2,           # 스택 앙상블 레벨 추가\n",
    "    time_limit=3600               # 학습에 충분한 시간 할당 (예: 1시간)\n",
    ")\n",
    "\n",
    "# 테스트 데이터에 대해 예측 (각 클래스별 확률 예측)\n",
    "preds_proba = predictor.predict_proba(test_data)\n",
    "test_data['채무 불이행 확률'] = preds_proba[1]  # 1번 클래스(채무 불이행)의 확률 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fad768c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T09:10:01.547214Z",
     "iopub.status.busy": "2025-03-22T09:10:01.546131Z",
     "iopub.status.idle": "2025-03-22T09:10:01.579765Z",
     "shell.execute_reply": "2025-03-22T09:10:01.578370Z"
    },
    "papermill": {
     "duration": 0.083521,
     "end_time": "2025-03-22T09:10:01.581699",
     "exception": false,
     "start_time": "2025-03-22T09:10:01.498178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoGluon을 이용한 예측 및 제출 파일 생성 완료!\n"
     ]
    }
   ],
   "source": [
    "# 제출 파일 불러오기 및 예측 결과 반영\n",
    "submission = pd.read_csv('/kaggle/input/non-fulfillment/sample_submission.csv')\n",
    "submission['채무 불이행 확률'] = test_data['채무 불이행 확률']\n",
    "submission.to_csv('submission_autogluon.csv', index=False)\n",
    "\n",
    "print(\"AutoGluon을 이용한 예측 및 제출 파일 생성 완료!\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6936185,
     "sourceId": 11122844,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3679.099143,
   "end_time": "2025-03-22T09:10:04.253982",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-22T08:08:45.154839",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
